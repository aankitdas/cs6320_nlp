{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test corpus: 512\n",
      "Test sentence: I booked two rooms four months in advance at the Talbott . We were placed on the top floor next to the elevators , which are used all night long . When speaking to the front desk , I was told that they were simply honoring my request for an upper floor , which I had requested for a better view . I am looking at a brick wall , and getting no sleep . He also told me that they had received complaints before from guests on the 16th floor , and were aware of the noise problem . Why then did they place us on this floor when the hotel is not totally booked ? A request for an upper floor does not constitute placing someone on the TOP floor and using that request to justify this . If you decide to stay here , request a room on a lower floor and away from the elevator ! I spoke at length when booking my two rooms about my preferences . This is simply poor treatment of a guest whom they believed would not complain .\n"
     ]
    }
   ],
   "source": [
    "with open(\"A1_DATASET/train.txt\", 'r') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "\n",
    "print(\"Size of test corpus:\",len(lines))\n",
    "\n",
    "test_sentence = lines[0]\n",
    "print('Test sentence:', test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>This hotel has the worst rooms we have stayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>We always stay at the Sheraton Chicago Hotel &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>We went to Chicago for my 2nd wedding annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>My husband and I stayed at the Hotel Monaco fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Any traveler who is loyal to a favorite hotel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "262  This hotel has the worst rooms we have stayed ...\n",
       "152  We always stay at the Sheraton Chicago Hotel &...\n",
       "193  We went to Chicago for my 2nd wedding annivers...\n",
       "421  My husband and I stayed at the Hotel Monaco fo...\n",
       "159  Any traveler who is loyal to a favorite hotel ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lines, columns=['reviews'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aanki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aanki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I booked two rooms four months in advance at the Talbott  We were placed on the top floor next to the elevators  which are used all night long  When speaking to the front desk  I was told that they were simply honoring my request for an upper floor  which I had requested for a better view  I am looking at a brick wall  and getting no sleep  He also told me that they had received complaints before from guests on the th floor  and were aware of the noise problem  Why then did they place us on this floor when the hotel is not totally booked  A request for an upper floor does not constitute placing someone on the TOP floor and using that request to justify this  If you decide to stay here  request a room on a lower floor and away from the elevator  I spoke at length when booking my two rooms about my preferences  This is simply poor treatment of a guest whom they believed would not complain '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuations and digit\n",
    "filtered_sent = test_sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "filtered_sent = ''.join([char for char in filtered_sent if not char.isdigit()])\n",
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the', 'Talbott', 'We', 'were', 'placed', 'on', 'the', 'top', 'floor', 'next', 'to', 'the', 'elevators', 'which', 'are', 'used', 'all', 'night', 'long', 'When', 'speaking', 'to', 'the', 'front', 'desk', 'I', 'was', 'told', 'that', 'they', 'were', 'simply', 'honoring', 'my', 'request', 'for', 'an', 'upper', 'floor', 'which', 'I', 'had', 'requested', 'for', 'a', 'better', 'view', 'I', 'am', 'looking', 'at', 'a', 'brick', 'wall', 'and', 'getting', 'no', 'sleep', 'He', 'also', 'told', 'me', 'that', 'they', 'had', 'received', 'complaints', 'before', 'from', 'guests', 'on', 'the', 'th', 'floor', 'and', 'were', 'aware', 'of', 'the', 'noise', 'problem', 'Why', 'then', 'did', 'they', 'place', 'us', 'on', 'this', 'floor', 'when', 'the', 'hotel', 'is', 'not', 'totally', 'booked', 'A', 'request', 'for', 'an', 'upper', 'floor', 'does', 'not', 'constitute', 'placing', 'someone', 'on', 'the', 'TOP', 'floor', 'and', 'using', 'that', 'request', 'to', 'justify', 'this', 'If', 'you', 'decide', 'to', 'stay', 'here', 'request', 'a', 'room', 'on', 'a', 'lower', 'floor', 'and', 'away', 'from', 'the', 'elevator', 'I', 'spoke', 'at', 'length', 'when', 'booking', 'my', 'two', 'rooms', 'about', 'my', 'preferences', 'This', 'is', 'simply', 'poor', 'treatment', 'of', 'a', 'guest', 'whom', 'they', 'believed', 'would', 'not', 'complain']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(filtered_sent)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booked two rooms four months advance Talbott placed top floor next elevators used night long speaking front desk told simply honoring request upper floor requested better view looking brick wall getting sleep also told received complaints guests th floor aware noise problem place us floor hotel totally booked request upper floor constitute placing someone TOP floor using request justify decide stay request room lower floor away elevator spoke length booking two rooms preferences simply poor treatment guest believed would complain\n"
     ]
    }
   ],
   "source": [
    "#removing stop words\n",
    "filtered_tokens = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "filtered_sent = ' '.join(filtered_tokens)\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'two', 'room', 'four', 'month', 'advanc', 'talbott', 'place', 'top', 'floor', 'next', 'elev', 'use', 'night', 'long', 'speak', 'front', 'desk', 'told', 'simpli', 'honor', 'request', 'upper', 'floor', 'request', 'better', 'view', 'look', 'brick', 'wall', 'get', 'sleep', 'also', 'told', 'receiv', 'complaint', 'guest', 'th', 'floor', 'awar', 'nois', 'problem', 'place', 'us', 'floor', 'hotel', 'total', 'book', 'request', 'upper', 'floor', 'constitut', 'place', 'someon', 'top', 'floor', 'use', 'request', 'justifi', 'decid', 'stay', 'request', 'room', 'lower', 'floor', 'away', 'elev', 'spoke', 'length', 'book', 'two', 'room', 'prefer', 'simpli', 'poor', 'treatment', 'guest', 'believ', 'would', 'complain']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stem_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to remove stop words and convert to lower case\n",
    "def preprocessing(sentence):\n",
    "    filtered_sent = sentence.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "    filtered_sent = ''.join([char for char in filtered_sent if not char.isdigit()]) #remove digits\n",
    "    word_tokens = word_tokenize(filtered_sent) #tokenize\n",
    "    stem_tokens = [stemmer.stem(word) for word in word_tokens] #stemming\n",
    "    filtered_tokens = [w for w in stem_tokens if not w.lower() in stop_words] #removing stopwords\n",
    "    filtered_sent = ' '.join(filtered_tokens) #joining the tokens\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing: I booked two rooms four months in advance at the Talbott . We were placed on the top floor next to the elevators , which are used all night long . When speaking to the front desk , I was told that they were simply honoring my request for an upper floor , which I had requested for a better view . I am looking at a brick wall , and getting no sleep . He also told me that they had received complaints before from guests on the 16th floor , and were aware of the noise problem . Why then did they place us on this floor when the hotel is not totally booked ? A request for an upper floor does not constitute placing someone on the TOP floor and using that request to justify this . If you decide to stay here , request a room on a lower floor and away from the elevator ! I spoke at length when booking my two rooms about my preferences . This is simply poor treatment of a guest whom they believed would not complain .\n",
      "After preprocessing: book two room four month advanc talbott place top floor next elev use night long speak front desk wa told simpli honor request upper floor request better view look brick wall get sleep also told receiv complaint befor guest th floor awar nois problem whi place us thi floor hotel total book request upper floor doe constitut place someon top floor use request justifi thi decid stay request room lower floor away elev spoke length book two room prefer thi simpli poor treatment guest believ would complain\n"
     ]
    }
   ],
   "source": [
    "test_sentence_clean = preprocessing(test_sentence)\n",
    "print(\"Before preprocessing:\", test_sentence)\n",
    "print(\"After preprocessing:\", test_sentence_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>If you have not tried the Millennium Knickerbo...</td>\n",
       "      <td>tri millennium knickerbock stay chicago stay e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>The hotel is almost always very helpful . This...</td>\n",
       "      <td>hotel almost alway veri help thi stay caus ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Swissotel was the cleanest hotel I have ever s...</td>\n",
       "      <td>swissotel wa cleanest hotel ever stay room bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>We just got back from a great weekend in Chica...</td>\n",
       "      <td>got back great weekend chicago complaint palme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Having had a great stay at the Monaco last Fal...</td>\n",
       "      <td>great stay monaco last fall friend wa disappoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "206  If you have not tried the Millennium Knickerbo...   \n",
       "429  The hotel is almost always very helpful . This...   \n",
       "268  Swissotel was the cleanest hotel I have ever s...   \n",
       "485  We just got back from a great weekend in Chica...   \n",
       "44   Having had a great stay at the Monaco last Fal...   \n",
       "\n",
       "                                                 clean  \n",
       "206  tri millennium knickerbock stay chicago stay e...  \n",
       "429  hotel almost alway veri help thi stay caus ret...  \n",
       "268  swissotel wa cleanest hotel ever stay room bat...  \n",
       "485  got back great weekend chicago complaint palme...  \n",
       "44   great stay monaco last fall friend wa disappoi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['reviews'].apply(lambda x: preprocessing(x))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just back from 5 night stay at Omni and would thoroughly recommend it . Staff bent over backwards to assist in anything , no matter how minute . Great location on magnificent mile and lots to do there both for adults and my 10yo daughter . If i had to find a fault it would be the extra charges , taxes etc for room service , bar and restaurant , but where is cheap these days ? Would definitely recommend it , especially for families .\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "test_sentence = lines[510]\n",
    "#test_sentence = \"the students like the assignment\"\n",
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Just', 'back', 'from', '5', 'night', 'stay', 'at', 'Omni', 'and', 'would', 'thoroughly', 'recommend', 'it', '.', 'Staff', 'bent', 'over', 'backwards', 'to', 'assist', 'in', 'anything', ',', 'no', 'matter', 'how', 'minute', '.', 'Great', 'location', 'on', 'magnificent', 'mile', 'and', 'lots', 'to', 'do', 'there', 'both', 'for', 'adults', 'and', 'my', '10yo', 'daughter', '.', 'If', 'i', 'had', 'to', 'find', 'a', 'fault', 'it', 'would', 'be', 'the', 'extra', 'charges', ',', 'taxes', 'etc', 'for', 'room', 'service', ',', 'bar', 'and', 'restaurant', ',', 'but', 'where', 'is', 'cheap', 'these', 'days', '?', 'Would', 'definitely', 'recommend', 'it', ',', 'especially', 'for', 'families', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_test_sent = preprocessing(test_sentence)\n",
    "test_tokens = nltk.word_tokenize(test_sentence)\n",
    "print(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({',': 5, 'and': 4, '.': 4, 'it': 3, 'to': 3, 'for': 3, 'would': 2, 'recommend': 2, 'Just': 1, 'back': 1, 'from': 1, '5': 1, 'night': 1, 'stay': 1, 'at': 1, 'Omni': 1, 'thoroughly': 1, 'Staff': 1, 'bent': 1, 'over': 1, 'backwards': 1, 'assist': 1, 'in': 1, 'anything': 1, 'no': 1, 'matter': 1, 'how': 1, 'minute': 1, 'Great': 1, 'location': 1, 'on': 1, 'magnificent': 1, 'mile': 1, 'lots': 1, 'do': 1, 'there': 1, 'both': 1, 'adults': 1, 'my': 1, '10yo': 1, 'daughter': 1, 'If': 1, 'i': 1, 'had': 1, 'find': 1, 'a': 1, 'fault': 1, 'be': 1, 'the': 1, 'extra': 1, 'charges': 1, 'taxes': 1, 'etc': 1, 'room': 1, 'service': 1, 'bar': 1, 'restaurant': 1, 'but': 1, 'where': 1, 'is': 1, 'cheap': 1, 'these': 1, 'days': 1, '?': 1, 'Would': 1, 'definitely': 1, 'especially': 1, 'families': 1})\n"
     ]
    }
   ],
   "source": [
    "unigrams = Counter(test_tokens)\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Just': 0.011627906976744186, 'back': 0.011627906976744186, 'from': 0.011627906976744186, '5': 0.011627906976744186, 'night': 0.011627906976744186, 'stay': 0.011627906976744186, 'at': 0.011627906976744186, 'Omni': 0.011627906976744186, 'and': 0.046511627906976744, 'would': 0.023255813953488372, 'thoroughly': 0.011627906976744186, 'recommend': 0.023255813953488372, 'it': 0.03488372093023256, '.': 0.046511627906976744, 'Staff': 0.011627906976744186, 'bent': 0.011627906976744186, 'over': 0.011627906976744186, 'backwards': 0.011627906976744186, 'to': 0.03488372093023256, 'assist': 0.011627906976744186, 'in': 0.011627906976744186, 'anything': 0.011627906976744186, ',': 0.05813953488372093, 'no': 0.011627906976744186, 'matter': 0.011627906976744186, 'how': 0.011627906976744186, 'minute': 0.011627906976744186, 'Great': 0.011627906976744186, 'location': 0.011627906976744186, 'on': 0.011627906976744186, 'magnificent': 0.011627906976744186, 'mile': 0.011627906976744186, 'lots': 0.011627906976744186, 'do': 0.011627906976744186, 'there': 0.011627906976744186, 'both': 0.011627906976744186, 'for': 0.03488372093023256, 'adults': 0.011627906976744186, 'my': 0.011627906976744186, '10yo': 0.011627906976744186, 'daughter': 0.011627906976744186, 'If': 0.011627906976744186, 'i': 0.011627906976744186, 'had': 0.011627906976744186, 'find': 0.011627906976744186, 'a': 0.011627906976744186, 'fault': 0.011627906976744186, 'be': 0.011627906976744186, 'the': 0.011627906976744186, 'extra': 0.011627906976744186, 'charges': 0.011627906976744186, 'taxes': 0.011627906976744186, 'etc': 0.011627906976744186, 'room': 0.011627906976744186, 'service': 0.011627906976744186, 'bar': 0.011627906976744186, 'restaurant': 0.011627906976744186, 'but': 0.011627906976744186, 'where': 0.011627906976744186, 'is': 0.011627906976744186, 'cheap': 0.011627906976744186, 'these': 0.011627906976744186, 'days': 0.011627906976744186, '?': 0.011627906976744186, 'Would': 0.011627906976744186, 'definitely': 0.011627906976744186, 'especially': 0.011627906976744186, 'families': 0.011627906976744186}\n"
     ]
    }
   ],
   "source": [
    "total_tokens = len(test_tokens)\n",
    "unigram_probabs = {word: count / total_tokens for word, count in unigrams.items()}\n",
    "print(unigram_probabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {'Just': Counter({'back': 1}), 'back': Counter({'from': 1}), 'from': Counter({'5': 1}), '5': Counter({'night': 1}), 'night': Counter({'stay': 1}), 'stay': Counter({'at': 1}), 'at': Counter({'Omni': 1}), 'Omni': Counter({'and': 1}), 'and': Counter({'would': 1, 'lots': 1, 'my': 1, 'restaurant': 1}), 'would': Counter({'thoroughly': 1, 'be': 1}), 'thoroughly': Counter({'recommend': 1}), 'recommend': Counter({'it': 2}), 'it': Counter({'.': 1, 'would': 1, ',': 1}), '.': Counter({'Staff': 1, 'Great': 1, 'If': 1}), 'Staff': Counter({'bent': 1}), 'bent': Counter({'over': 1}), 'over': Counter({'backwards': 1}), 'backwards': Counter({'to': 1}), 'to': Counter({'assist': 1, 'do': 1, 'find': 1}), 'assist': Counter({'in': 1}), 'in': Counter({'anything': 1}), 'anything': Counter({',': 1}), ',': Counter({'no': 1, 'taxes': 1, 'bar': 1, 'but': 1, 'especially': 1}), 'no': Counter({'matter': 1}), 'matter': Counter({'how': 1}), 'how': Counter({'minute': 1}), 'minute': Counter({'.': 1}), 'Great': Counter({'location': 1}), 'location': Counter({'on': 1}), 'on': Counter({'magnificent': 1}), 'magnificent': Counter({'mile': 1}), 'mile': Counter({'and': 1}), 'lots': Counter({'to': 1}), 'do': Counter({'there': 1}), 'there': Counter({'both': 1}), 'both': Counter({'for': 1}), 'for': Counter({'adults': 1, 'room': 1, 'families': 1}), 'adults': Counter({'and': 1}), 'my': Counter({'10yo': 1}), '10yo': Counter({'daughter': 1}), 'daughter': Counter({'.': 1}), 'If': Counter({'i': 1}), 'i': Counter({'had': 1}), 'had': Counter({'to': 1}), 'find': Counter({'a': 1}), 'a': Counter({'fault': 1}), 'fault': Counter({'it': 1}), 'be': Counter({'the': 1}), 'the': Counter({'extra': 1}), 'extra': Counter({'charges': 1}), 'charges': Counter({',': 1}), 'taxes': Counter({'etc': 1}), 'etc': Counter({'for': 1}), 'room': Counter({'service': 1}), 'service': Counter({',': 1}), 'bar': Counter({'and': 1}), 'restaurant': Counter({',': 1}), 'but': Counter({'where': 1}), 'where': Counter({'is': 1}), 'is': Counter({'cheap': 1}), 'cheap': Counter({'these': 1}), 'these': Counter({'days': 1}), 'days': Counter({'?': 1}), '?': Counter({'Would': 1}), 'Would': Counter({'definitely': 1}), 'definitely': Counter({'recommend': 1}), 'especially': Counter({'for': 1}), 'families': Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "bigrams = defaultdict(Counter)\n",
    "for i in range(len(test_tokens)-1):\n",
    "    w1,w2 = test_tokens[i], test_tokens[i+1]\n",
    "    bigrams[w1][w2] += 1\n",
    "\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'Just': {'back': 1.0}, 'back': {'from': 1.0}, 'from': {'5': 1.0}, '5': {'night': 1.0}, 'night': {'stay': 1.0}, 'stay': {'at': 1.0}, 'at': {'Omni': 1.0}, 'Omni': {'and': 1.0}, 'and': {'would': 0.25, 'lots': 0.25, 'my': 0.25, 'restaurant': 0.25}, 'would': {'thoroughly': 0.5, 'be': 0.5}, 'thoroughly': {'recommend': 1.0}, 'recommend': {'it': 1.0}, 'it': {'.': 0.3333333333333333, 'would': 0.3333333333333333, ',': 0.3333333333333333}, '.': {'Staff': 0.25, 'Great': 0.25, 'If': 0.25}, 'Staff': {'bent': 1.0}, 'bent': {'over': 1.0}, 'over': {'backwards': 1.0}, 'backwards': {'to': 1.0}, 'to': {'assist': 0.3333333333333333, 'do': 0.3333333333333333, 'find': 0.3333333333333333}, 'assist': {'in': 1.0}, 'in': {'anything': 1.0}, 'anything': {',': 1.0}, ',': {'no': 0.2, 'taxes': 0.2, 'bar': 0.2, 'but': 0.2, 'especially': 0.2}, 'no': {'matter': 1.0}, 'matter': {'how': 1.0}, 'how': {'minute': 1.0}, 'minute': {'.': 1.0}, 'Great': {'location': 1.0}, 'location': {'on': 1.0}, 'on': {'magnificent': 1.0}, 'magnificent': {'mile': 1.0}, 'mile': {'and': 1.0}, 'lots': {'to': 1.0}, 'do': {'there': 1.0}, 'there': {'both': 1.0}, 'both': {'for': 1.0}, 'for': {'adults': 0.3333333333333333, 'room': 0.3333333333333333, 'families': 0.3333333333333333}, 'adults': {'and': 1.0}, 'my': {'10yo': 1.0}, '10yo': {'daughter': 1.0}, 'daughter': {'.': 1.0}, 'If': {'i': 1.0}, 'i': {'had': 1.0}, 'had': {'to': 1.0}, 'find': {'a': 1.0}, 'a': {'fault': 1.0}, 'fault': {'it': 1.0}, 'be': {'the': 1.0}, 'the': {'extra': 1.0}, 'extra': {'charges': 1.0}, 'charges': {',': 1.0}, 'taxes': {'etc': 1.0}, 'etc': {'for': 1.0}, 'room': {'service': 1.0}, 'service': {',': 1.0}, 'bar': {'and': 1.0}, 'restaurant': {',': 1.0}, 'but': {'where': 1.0}, 'where': {'is': 1.0}, 'is': {'cheap': 1.0}, 'cheap': {'these': 1.0}, 'these': {'days': 1.0}, 'days': {'?': 1.0}, '?': {'Would': 1.0}, 'Would': {'definitely': 1.0}, 'definitely': {'recommend': 1.0}, 'especially': {'for': 1.0}, 'families': {'.': 1.0}})\n"
     ]
    }
   ],
   "source": [
    "bigram_probabs = defaultdict(dict)\n",
    "for w1 in bigrams:\n",
    "    total_w1 = unigrams[w1]\n",
    "    for w2 in bigrams[w1]:\n",
    "        bigram_probabs[w1][w2] = bigrams[w1][w2] / total_w1\n",
    "\n",
    "print(bigram_probabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Probabilities:\n",
      "P(Just) = 0.0116\n",
      "\n",
      "Bigram Probabilities:\n",
      "P(back|Just) = 1.0000\n",
      "P(from|back) = 1.0000\n",
      "P(5|from) = 1.0000\n",
      "P(night|5) = 1.0000\n",
      "P(stay|night) = 1.0000\n",
      "P(at|stay) = 1.0000\n",
      "P(Omni|at) = 1.0000\n",
      "P(and|Omni) = 1.0000\n",
      "P(would|and) = 0.2500\n",
      "P(thoroughly|would) = 0.5000\n",
      "P(recommend|thoroughly) = 1.0000\n",
      "P(it|recommend) = 1.0000\n",
      "P(.|it) = 0.3333\n",
      "P(Staff|.) = 0.2500\n",
      "P(bent|Staff) = 1.0000\n",
      "P(over|bent) = 1.0000\n",
      "P(backwards|over) = 1.0000\n",
      "P(to|backwards) = 1.0000\n",
      "P(assist|to) = 0.3333\n",
      "P(in|assist) = 1.0000\n",
      "P(anything|in) = 1.0000\n",
      "P(,|anything) = 1.0000\n",
      "P(no|,) = 0.2000\n",
      "P(matter|no) = 1.0000\n",
      "P(how|matter) = 1.0000\n",
      "P(minute|how) = 1.0000\n",
      "P(.|minute) = 1.0000\n",
      "P(location|Great) = 1.0000\n",
      "P(on|location) = 1.0000\n",
      "P(magnificent|on) = 1.0000\n",
      "P(mile|magnificent) = 1.0000\n",
      "P(and|mile) = 1.0000\n",
      "P(to|lots) = 1.0000\n",
      "P(there|do) = 1.0000\n",
      "P(both|there) = 1.0000\n",
      "P(for|both) = 1.0000\n",
      "P(adults|for) = 0.3333\n",
      "P(and|adults) = 1.0000\n",
      "P(10yo|my) = 1.0000\n",
      "P(daughter|10yo) = 1.0000\n",
      "P(.|daughter) = 1.0000\n",
      "P(i|If) = 1.0000\n",
      "P(had|i) = 1.0000\n",
      "P(to|had) = 1.0000\n",
      "P(a|find) = 1.0000\n",
      "P(fault|a) = 1.0000\n",
      "P(it|fault) = 1.0000\n",
      "P(the|be) = 1.0000\n",
      "P(extra|the) = 1.0000\n",
      "P(charges|extra) = 1.0000\n",
      "P(,|charges) = 1.0000\n",
      "P(etc|taxes) = 1.0000\n",
      "P(for|etc) = 1.0000\n",
      "P(service|room) = 1.0000\n",
      "P(,|service) = 1.0000\n",
      "P(and|bar) = 1.0000\n",
      "P(,|restaurant) = 1.0000\n",
      "P(where|but) = 1.0000\n",
      "P(is|where) = 1.0000\n",
      "P(cheap|is) = 1.0000\n",
      "P(these|cheap) = 1.0000\n",
      "P(days|these) = 1.0000\n",
      "P(?|days) = 1.0000\n",
      "P(Would|?) = 1.0000\n",
      "P(definitely|Would) = 1.0000\n",
      "P(recommend|definitely) = 1.0000\n",
      "P(for|especially) = 1.0000\n",
      "P(.|families) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram Probabilities:\")\n",
    "for word, prob in unigram_probabs.items():\n",
    "    print(f\"P({word}) = {prob:.4f}\")\n",
    "    break\n",
    "\n",
    "print(\"\\nBigram Probabilities:\")\n",
    "for w1 in bigram_probabs:\n",
    "    for w2 in bigram_probabs[w1]:\n",
    "        print(f\"P({w2}|{w1}) = {bigram_probabs[w1][w2]:.4f}\")\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate unigrams and bigrams\n",
    "def calc_ngrams(clean_sent):\n",
    "    list_unigrams = []\n",
    "    list_bigrams = []\n",
    "    tokens = nltk.word_tokenize(clean_sent)\n",
    "    \n",
    "    unigrams = Counter(tokens)\n",
    "    total_tokens = len(tokens)\n",
    "    unigram_probabs = {word: count / total_tokens for word, count in unigrams.items()}\n",
    "    for word, prob in unigram_probabs.items():\n",
    "        list_unigrams.append(f\"P({word}) = {prob:.4f}\")\n",
    "\n",
    "\n",
    "    bigrams = defaultdict(Counter)\n",
    "    for i in range(len(tokens)-1):\n",
    "        w1,w2 = tokens[i], tokens[i+1]\n",
    "        bigrams[w1][w2] += 1\n",
    "    bigram_probabs = defaultdict(dict)\n",
    "    for w1 in bigrams:\n",
    "        total_w1 = unigrams[w1]\n",
    "        for w2 in bigrams[w1]:\n",
    "            bigram_probabs[w1][w2] = bigrams[w1][w2] / total_w1\n",
    "    for w1 in bigram_probabs:\n",
    "        for w2 in bigram_probabs[w1]:\n",
    "            list_bigrams.append(f\"P({w2}|{w1}) = {bigram_probabs[w1][w2]:.4f}\")\n",
    "\n",
    "    return list_unigrams, list_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>I got a Sunday night stay for only $ 50 off of...</td>\n",
       "      <td>got sunday night stay onli pricelinecom would ...</td>\n",
       "      <td>[P(got) = 0.0100, P(sunday) = 0.0050, P(night)...</td>\n",
       "      <td>[P(sunday|got) = 0.5000, P(ohar|got) = 0.5000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Hotel Monaco is in a really great location , o...</td>\n",
       "      <td>hotel monaco realli great locat onli block awa...</td>\n",
       "      <td>[P(hotel) = 0.0115, P(monaco) = 0.0115, P(real...</td>\n",
       "      <td>[P(monaco|hotel) = 1.0000, P(realli|monaco) = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>in the windy city , this is a very good place....</td>\n",
       "      <td>windi citi thi veri good placeamaz room servic...</td>\n",
       "      <td>[P(windi) = 0.0435, P(citi) = 0.0435, P(thi) =...</td>\n",
       "      <td>[P(citi|windi) = 1.0000, P(thi|citi) = 1.0000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>My girlfriends and I stayed 4 nights at the Ta...</td>\n",
       "      <td>girlfriend stay night talbott return home satu...</td>\n",
       "      <td>[P(girlfriend) = 0.0169, P(stay) = 0.0169, P(n...</td>\n",
       "      <td>[P(stay|girlfriend) = 1.0000, P(night|stay) = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>After some deliberation I booked the Sofitel W...</td>\n",
       "      <td>deliber book sofitel water tower place night s...</td>\n",
       "      <td>[P(deliber) = 0.0105, P(book) = 0.0105, P(sofi...</td>\n",
       "      <td>[P(book|deliber) = 1.0000, P(sofitel|book) = 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "108  I got a Sunday night stay for only $ 50 off of...   \n",
       "228  Hotel Monaco is in a really great location , o...   \n",
       "416  in the windy city , this is a very good place....   \n",
       "360  My girlfriends and I stayed 4 nights at the Ta...   \n",
       "223  After some deliberation I booked the Sofitel W...   \n",
       "\n",
       "                                                 clean  \\\n",
       "108  got sunday night stay onli pricelinecom would ...   \n",
       "228  hotel monaco realli great locat onli block awa...   \n",
       "416  windi citi thi veri good placeamaz room servic...   \n",
       "360  girlfriend stay night talbott return home satu...   \n",
       "223  deliber book sofitel water tower place night s...   \n",
       "\n",
       "                                              unigrams  \\\n",
       "108  [P(got) = 0.0100, P(sunday) = 0.0050, P(night)...   \n",
       "228  [P(hotel) = 0.0115, P(monaco) = 0.0115, P(real...   \n",
       "416  [P(windi) = 0.0435, P(citi) = 0.0435, P(thi) =...   \n",
       "360  [P(girlfriend) = 0.0169, P(stay) = 0.0169, P(n...   \n",
       "223  [P(deliber) = 0.0105, P(book) = 0.0105, P(sofi...   \n",
       "\n",
       "                                               bigrams  \n",
       "108  [P(sunday|got) = 0.5000, P(ohar|got) = 0.5000,...  \n",
       "228  [P(monaco|hotel) = 1.0000, P(realli|monaco) = ...  \n",
       "416  [P(citi|windi) = 1.0000, P(thi|citi) = 1.0000,...  \n",
       "360  [P(stay|girlfriend) = 1.0000, P(night|stay) = ...  \n",
       "223  [P(book|deliber) = 1.0000, P(sofitel|book) = 1...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['unigrams','bigrams']] = df['clean'].apply(lambda x: pd.Series(calc_ngrams(x)))\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"A1_DATASET/val.txt\", 'r') as file:\n",
    "    test_lines = [line.rstrip() for line in file]\n",
    "\n",
    "len(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>My husband and I were very excited to be stayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Had a week long stay at the Hilton on south Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>If you love Brick Walls and Alleyways , then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Booked a room w/ a queen bed for 2 nights for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stayed there three nights from 4/17/09 through...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews\n",
       "65  My husband and I were very excited to be stayi...\n",
       "66  Had a week long stay at the Hilton on south Mi...\n",
       "67  If you love Brick Walls and Alleyways , then t...\n",
       "68  Booked a room w/ a queen bed for 2 nights for ...\n",
       "69  Stayed there three nights from 4/17/09 through..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test_lines, columns=['reviews'])\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just back from 5 night stay at Omni and would thoroughly recommend it . Staff bent over backwards to assist in anything , no matter how minute . Great location on magnificent mile and lots to do there both for adults and my 10yo daughter . If i had to find a fault it would be the extra charges , taxes etc for room service , bar and restaurant , but where is cheap these days ? Would definitely recommend it , especially for families .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent = lines[510]\n",
    "train_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you love Brick Walls and Alleyways , then this view is for you . I asked for a room facing the river , I get a room facing a Brick Wall . That really pissed me off . From all the great reviews , I was expecting better . Before I came here , I stayed in a Hyatt in NYC , and that was awesome . There was nothing about the hotel that blew me away . The wine hour was ok . I was hoping there would be something better food , but I guess that 's why it 's a wine hour . I ordered room service one night . There was n't really anywhere to eat it , so I had to eat it on my bed to watch tv . This was my first time coming to Chicago , and I think it will be my last . Just thoroughly disappointed .\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = test_lines[67]\n",
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back night stay omni would thoroughli recommend staff bent backward assist anyth matter minut great locat magnific mile lot adult yo daughter find fault would extra charg tax etc room servic bar restaur cheap day would definit recommend especi famili\n",
      "love brick wall alleyway thi view ask room face river get room face brick wall realli piss great review wa expect better befor came stay hyatt nyc wa awesom wa noth hotel blew away wine hour wa ok wa hope would someth better food guess whi wine hour order room servic one night wa nt realli anywher eat eat bed watch tv thi wa first time come chicago think last thoroughli disappoint\n"
     ]
    }
   ],
   "source": [
    "clean_train_sent = preprocessing(train_sent)\n",
    "clean_test_sent = preprocessing(test_sent)\n",
    "print(clean_train_sent)\n",
    "print(clean_test_sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a vocab from training data\n",
    "def handle_unk(data, threshold=1):\n",
    "    word_counts = Counter()\n",
    "    for sentences in data:\n",
    "        sentences = preprocessing(sentences)\n",
    "        sentences = sentences.lower().split()\n",
    "        word_counts.update(sentences)\n",
    "    \n",
    "    vocab = {word for word, count in word_counts.items() if count > threshold}\n",
    "    return word_counts, vocab\n",
    "\n",
    "word_counts, vocab = handle_unk(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rude', 'clientel', 'lukewarm', 'plug', 'orchid', 'neat', 'romant', 'dirt', 'execut', 'fresh', 'success', 'connect', 'flush', 'fortun', 'begun', 'expir', 'work', 'jump', 'cabinet', 'ie', 'regard', 'clean', 'delight', 'engin', 'descript', 'handsom', 'transfer', 'year', 'suck', 'forgotten', 'daughter', 'said', 'inspect', 'secur', 'recogn', 'indoor', 'mildew', 'brother', 'averag', 'claim', 'firework', 'overnight', 'futur', 'fault', 'usa', 'entertain', 'insur', 'waitress', 'keep', 'jame', 'upcom', 'shut', 'minu', 'surround', 'needless', 'slap', 'rehab', 'shampoo', 'afternoon', 'ideal', 'westin', 'machin', 'eventu', 'night', 'feel', 'ask', 'middl', 'place', 'anniversari', 'supervis', 'unprofession', 'remot', 'noth', 'woken', 'lcd', 'minibar', 'matter', 'fairli', 'drank', 'nicer', 'lotion', 'theater', 'enorm', 'somewher', 'tie', 'sight', 'kiss', 'fluffi', 'track', 'sightse', 'thoroughli', 'bathrob', 'bump', 'humid', 'hesit', 'kind', 'blood', 'lobbi', 'compel', 'common', 'challeng', 'fairmont', 'wasnt', 'hot', 'chose', 'pleasent', 'rip', 'thi', 'excus', 'th', 'cd', 'vacuum', 'drawback', 'spot', 'bedroom', 'sidewalk', 'director', 'final', 'museum', 'chop', 'quickli', 'hotwir', 'soon', 'asid', 'mix', 'alon', 'scratch', 'physic', 'importantli', 'toiletri', 'forward', 'wake', 'pl', 'octob', 'besid', 'wash', 'burnham', 'cruis', 'sleeper', 'ani', 'convers', 'prove', 'incorrect', 'outlet', 'speed', 'cart', 'weird', 'close', 'tough', 'return', 'dear', 'ammen', 'boyfriend', 'watch', 'newer', 'compani', 'perfect', 'diamond', 'class', 'mainten', 'strike', 'web', 'set', 'new', 'consierg', 'pair', 'favourit', 'real', 'along', 'bellhop', 'without', 'thanksgiv', 'sparkl', 'son', 'courtesi', 'monoco', 'parent', 'itchi', 'breez', 'slip', 'repair', 'ohar', 'nordstrom', 'look', 'ledg', 'kiehl', 'beat', 'icebucket', 'bargain', 'uninvit', 'kitchen', 'affluent', 'fantast', 'utensil', 'instruct', 'us', 'didnt', 'kick', 'recept', 'h', 'lift', 'west', 'centr', 'stay', 'liter', 'dish', 'woman', 'staff', 'particularli', 'minor', 'luxuri', 'sheet', 'support', 'run', 'treasur', 'key', 'research', 'bill', 'involv', 'avoid', 'coolest', 'newspap', 'fli', 'met', 'reach', 'self', 'downtown', 'email', 'tend', 'theatr', 'everyon', 'shave', 'reason', 'inform', 'natur', 'giant', 'peninsula', 'oatmeal', 'pillow', 'simpli', 'thru', 'midway', 'unpleas', 'nite', 'social', 'famili', 'inconsist', 'relax', 'freshli', 'separ', 'freez', 'god', 'bath', 'mouthwash', 'membership', 'factori', 'equival', 'cheap', 'morn', 'face', 'overlook', 'slow', 'train', 'brand', 'bad', 'dumpi', 'refer', 'twin', 'amalfi', 'rain', 'studio', 'fare', 'wish', 'either', 'beverag', 'remodel', 'cap', 'suit', 'houseclean', 'sister', 'muffin', 'exampl', 'tour', 'novemb', 'use', 'stall', 'ampl', 'lure', 'acknowledg', 'purchas', 'televis', 'somehow', 'odor', 'regenc', 'money', 'cleaner', 'someon', 'area', 'follow', 'loop', 'path', 'hyatt', 'extra', 'singl', 'hospit', 'stori', 'suffer', 'deni', 'drove', 'reconfirm', 'pool', 'homey', 'rental', 'howev', 'job', 'usag', 'soap', 'entre', 'chanc', 'fast', 'comparison', 'church', 'egg', 'window', 'discov', 'aspect', 'rm', 'move', 'local', 'labor', 'french', 'distanc', 'steak', 'tradit', 'benefit', 'show', 'arm', 'abl', 'awaken', 'poorli', 'magnifici', 'quikbook', 'chines', 'radio', 'crab', 'hour', 'back', 'sent', 'realli', 'guestroom', 'gold', 'numer', 'mattress', 'seattl', 'nap', 'manhattan', 'sleepless', 'danish', 'tripl', 'tag', 'ikea', 'crack', 'horribl', 'notifi', 'superior', 'stick', 'pipe', 'respons', 'arriv', 'sensibl', 'includ', 'curt', 'themselv', 'impress', 'im', 'spite', 'spaciou', 'interest', 'bug', 'shop', 'weather', 'massag', 'shoe', 'cramp', 'less', 'ladi', 'trap', 'maci', 'walkin', 'painless', 'panhandl', 'meat', 'redeem', 'dozen', 'mainli', 'detail', 'music', 'unavail', 'christma', 'posit', 'recent', 'sheraton', 'closer', 'dinner', 'inexcus', 'parad', 'serv', 'wine', 'starwood', 'celebr', 'began', 'baffl', 'friday', 'tacki', 'turn', 'miss', 'typic', 'corpor', 'older', 'chosen', 'introduct', 'paint', 'photo', 'robe', 'rock', 'orient', 'complaint', 'contact', 'eve', 'aesthet', 'complet', 'marathon', 'done', 'ceremoni', 'appear', 'occas', 'member', 'stare', 'match', 'knock', 'delux', 'teen', 'wo', 'bring', 'determin', 'address', 'togeth', 'wrote', 'assur', 'item', 'inadequ', 'everi', 'evid', 'rate', 'heart', 'condit', 'cobb', 'allegro', 'lug', 'trim', 'enjoy', 'spread', 'hello', 'ae', 'incred', 'california', 'bear', 'daili', 'respect', 'ill', 'aug', 'suspect', 'public', 'commun', 'sunday', 'tire', 'yet', 'salti', 'chicago', 'hallway', 'primehous', 'adjust', 'spotless', 'properli', 'road', 'chip', 'straight', 'midday', 'loung', 'brag', 'joke', 'dingi', 'resolv', 'choic', 'topnotch', 'holder', 'town', 'exact', 'cater', 'anyway', 'uniformli', 'moldi', 'wick', 'spg', 'bellman', 'safe', 'drink', 'flower', 'hancock', 'beer', 'beauti', 'easi', 'hall', 'hum', 'past', 'waiter', 'inn', 'apolog', 'multipl', 'friendli', 'embarrass', 'discount', 'accommod', 'boat', 'unwelcom', 'color', 'spent', 'talk', 'jewel', 'abil', 'alright', 'channel', 'immedi', 'chicken', 'burn', 'cheaper', 'friend', 'aquarium', 'twenti', 'affect', 'upsid', 'pick', 'big', 'tub', 'empti', 'send', 'ha', 'becaus', 'someth', 'longer', 'greet', 'impolit', 'problem', 'term', 'complimentari', 'feet', 'least', 'server', 'omni', 'godsend', 'finish', 'constant', 'current', 'explain', 'away', 'blue', 'leg', 'put', 'blame', 'lower', 'author', 'aveda', 'schrager', 'anticip', 'x', 'write', 'vehicl', 'goug', 'gestur', 'flight', 'hilton', 'effici', 'partial', 'gear', 'suppli', 'contemporari', 'though', 'plasma', 'recommend', 'choos', 'profession', 'sofitel', 'registr', 'requir', 'roll', 'eye', 'see', 'gem', 'tri', 'winter', 'thin', 'differ', 'inroom', 'outstand', 'lesson', 'highway', 'certainli', 'classic', 'equal', 'disappoint', 'occasion', 'amaz', 'john', 'onli', 'suggest', 'hill', 'form', 'luggag', 'disinterest', 'stuffi', 'delay', 'wind', 'built', 'idiot', 'fountain', 'concret', 'cta', 'drunk', 'slept', 'open', 'emerg', 'travel', 'continu', 'portion', 'prompt', 'aw', 'materi', 'steal', 'fall', 'wors', 'elev', 'everytim', 'give', 'small', 'enter', 'heat', 'meet', 'water', 'devic', 'ipod', 'terrif', 'theme', 'ever', 'limit', 'bathroom', 'way', 'industri', 'avail', 'took', 'cream', 'wand', 'privat', 'suppos', 'cleanli', 'find', 'scrape', 'buse', 'artwork', 'highest', 'starbuck', 'jungl', 'littl', 'filet', 'short', 'lot', 'tax', 'wife', 'river', 'want', 'comput', 'donut', 'know', 'fourth', 'bar', 'eno', 'el', 'andor', 'effort', 'homeless', 'tea', 'ca', 'beach', 'plumb', 'appet', 'gap', 'knickerbock', 'cowork', 'mayb', 'letter', 'danc', 'decad', 'tuck', 'market', 'bu', 'whatsoev', 'confirm', 'bldg', 'traffic', 'anymor', 'wireless', 'confront', 'even', 'knowledg', 'order', 'sorri', 'caus', 'possibl', 'goldfish', 'held', 'program', 'kept', 'later', 'whether', 'tourist', 'car', 'thorough', 'vent', 'count', 'obtain', 'mediocr', 'caught', 'accomplish', 'experienc', 'prime', 'upset', 'metal', 'scale', 'concierg', 'asian', 'coupon', 'ourselv', 'reduc', 'stylish', 'laid', 'newli', 'washington', 'rang', 'client', 'italian', 'dent', 'downgrad', 'l', 'host', 'door', 'pm', 'low', 'gino', 'system', 'european', 'granit', 'architectur', 'cloud', 'never', 'temp', 'lap', 'glanc', 'repli', 'stuck', 'busi', 'overal', 'backward', 'deco', 'flood', 'click', 'also', 'reluctantli', 'hop', 'late', 'pro', 'onc', 'brick', 'proper', 'storag', 'ps', 'hair', 'forc', 'print', 'ground', 'replenish', 'pricelin', 'virtual', 'contain', 'ahead', 'checkout', 'nbc', 'terrac', 'discuss', 'although', 'oliv', 'thfloor', 'roof', 'salt', 'laptop', 'behind', 'fulli', 'compart', 'navi', 'con', 'august', 'staf', 'comfort', 'learn', 'borrow', 'uno', 'strongli', 'mostli', 'dim', 'wednesday', 'vibe', 'basement', 'exceed', 'mail', 'stuff', 'faucet', 'impecc', 'home', 'gripe', 'travelzoo', 'cell', 'moment', 'gave', 'obnoxi', 'structur', 'per', 'agent', 'cabl', 'speaker', 'maker', 'warrant', 'unabl', 'treat', 'good', 'box', 'feather', 'popular', 'golden', 'dure', 'offer', 'fruit', 'pressur', 'difficult', 'fell', 'pretend', 'dirti', 'special', 'makeov', 'blew', 'hold', 'construct', 'stood', 'reccomend', 'dip', 'two', 'workout', 'flexibl', 'tribun', 'joe', 'event', 'simpl', 'book', 'tasti', 'break', 'anytim', 'constantli', 'schedul', 'lodg', 'metro', 'cup', 'huge', 'chic', 'nicest', 'terribl', 'entranc', 'frankli', 'incid', 'poor', 'name', 'practic', 'dead', 'okay', 'rel', 'tell', 'corridor', 'anoth', 'block', 'reflect', 'mansion', 'retriev', 'assum', 'rooftop', 'plu', 'ratti', 'deep', 'hrh', 'first', 'custom', 'sexi', 'buddi', 'cool', 'departur', 'grout', 'forth', 'pricelinecom', 'closest', 'pari', 'conceirg', 'worri', 'par', 'thur', 'adjac', 'snack', 'doorman', 'unfriendli', 'crummi', 'bose', 'nt', 'ambassador', 'card', 'hampton', 'join', 'maintain', 'boy', 'screw', 'attach', 'amount', 'effect', 'milk', 'process', 'luck', 'grandma', 'bed', 'sign', 'price', 'appal', 'spray', 'upon', 'decent', 'manag', 'realiz', 'wide', 'jaym', 'contrari', 'ten', 'level', 'cleanest', 'board', 'uncomfort', 'old', 'directli', 'none', 'sold', 'contract', 'alreadi', 'sever', 'actual', 'cancel', 'remind', 'peac', 'beaten', 'occupi', 'w', 'aggrav', 'talbott', 'def', 'btw', 'twice', 'mind', 'soak', 'unrespons', 'june', 'ticket', 'suffici', 'suburb', 'shame', 'neg', 'link', 'guest', 'red', 'line', 'shine', 'cave', 'blow', 'motel', 'marbl', 'reciev', 'midnight', 'gener', 'stair', 'approach', 'think', 'els', 'husband', 'fridg', 'network', 'sleep', 'rest', 'awesom', 'week', 'initi', 'lead', 'four', 'sleek', 'honeymoon', 'slide', 'result', 'exist', 'defin', 'conrad', 'thing', 'credit', 'nearli', 'news', 'yell', 'ambianc', 'push', 'whi', 'bottom', 'unless', 'holiday', 'banana', 'spectacular', 'cooki', 'forgot', 'decid', 'street', 'checkin', 'wont', 'bent', 'comfi', 'girl', 'kid', 'could', 'direct', 'drive', 'incur', 'microwav', 'extens', 'advis', 'time', 'specif', 'investig', 'earn', 'cheesi', 'min', 'earlier', 'six', 'influenc', 'notch', 'control', 'well', 'nonsmok', 'ran', 'game', 'premis', 'hr', 'largest', 'girlfriend', 'strip', 'underwhelm', 'biggest', 'worth', 'equip', 'congest', 'blender', 'bulb', 'occur', 'grill', 'argu', 'manner', 'nasti', 'nd', 'float', 'flavor', 'soda', 'fine', 'downsid', 'bewar', 'intim', 'remov', 'fold', 'size', 'affina', 'blanket', 'customari', 'larger', 'belong', 'power', 'basic', 'age', 'weak', 'smell', 'champagn', 'smooth', 'world', 'undergo', 'shock', 'massiv', 'memori', 'honor', 'reclean', 'plane', 'institut', 'eat', 'hanger', 'awar', 'welcom', 'valu', 'activ', 'bartend', 'sensit', 'pricey', 'told', 'worn', 'american', 'wastebasket', 'floor', 'brief', 'seen', 'via', 'luckili', 'stock', 'base', 'whatev', 'indic', 'enough', 'father', 'buffet', 'ye', 'quick', 'cane', 'basket', 'bottl', 'forget', 'packag', 'housekeep', 'view', 'reassur', 'sill', 'ad', 'flew', 'mile', 'mph', 'drake', 'rush', 'quaint', 'nightlif', 'eaten', 'chi', 'interior', 'much', 'miser', 'peopl', 'pleasantli', 'soso', 'account', 'dump', 'bumper', 'damn', 'hotel', 'depart', 'unimpress', 'sofa', 'light', 'europ', 'bolt', 'aaa', 'noon', 'explor', 'anywher', 'hor', 'hate', 'homewood', 'visit', 'mag', 'struggl', 'airi', 'review', 'fail', 'bin', 'technolog', 'locker', 'rent', 'marriott', 'gift', 'sort', 'main', 'tripadvisor', 'attend', 'ignor', 'add', 'unaccept', 'everyth', 'understand', 'glad', 'smile', 'receiv', 'headquart', 'durat', 'volum', 'alot', 'mold', 'noisi', 'inde', 'great', 'brunch', 'rollaway', 'begin', 'degre', 'march', 'mouth', 'express', 'nervou', 'easili', 'extrem', 'lockwood', 'conveni', 'frequent', 'cloth', 'automat', 'clear', 'similarli', 'incompet', 'serious', 'type', 'appoint', 'case', 'polici', 'meridian', 'procedur', 'consequ', 'complain', 'drop', 'dave', 'need', 'lamp', 'articl', 'sutton', 'sauc', 'deliveri', 'chees', 'probabl', 'verifi', 'taken', 'pleasant', 'guess', 'dessert', 'eleg', 'pastri', 'pen', 'pleas', 'horror', 'care', 'assign', 'meantim', 'crumb', 'ouch', 'certain', 'hung', 'ridicul', 'site', 'imposs', 'vaniti', 'entitl', 'shape', 'carri', 'around', 'center', 'compliment', 'sens', 'went', 'day', 'renov', 'jacuzzi', 'spa', 'hope', 'admit', 'high', 'movi', 'replac', 'bellmen', 'qualiti', 'mirror', 'grati', 'advisor', 'sure', 'select', 'attent', 'neighbor', 'lock', 'pet', 'slight', 'garag', 'jean', 'tower', 'ryan', 'today', 'session', 'style', 'downstair', 'elimin', 'properti', 'airlin', 'hvac', 'insid', 'word', 'dollar', 'upstair', 'opt', 'troubl', 'take', 'yeah', 'dock', 'across', 'mall', 'repres', 'pepper', 'north', 'plate', 'deck', 'situat', 'free', 'scene', 'consist', 'storm', 'wonder', 'imagin', 'might', 'listen', 'abysm', 'wifi', 'sylvia', 'sometim', 'headach', 'trader', 'atmospher', 'felt', 'mine', 'breath', 'believ', 'outrag', 'copi', 'among', 'doubl', 'stark', 'befor', 'adult', 'rice', 'sell', 'etc', 'sound', 'everybodi', 'angi', 'sinatra', 'overhaul', 'kitti', 'fix', 'must', 'sale', 'odd', 'scent', 'miracl', 'updat', 'previou', 'visitor', 'slam', 'young', 'decor', 'regular', 'thier', 'opposit', 'valentin', 'nightclub', 'pictur', 'croissant', 'sudden', 'unusu', 'due', 'cheapest', 'alley', 'bedspread', 'stress', 'plain', 'slightli', 'servic', 'favor', 'import', 'store', 'bid', 'crown', 'echo', 'sit', 'turndown', 'wear', 'neck', 'towel', 'ambienc', 'magnific', 'alert', 'ring', 'expedia', 'ton', 'downhil', 'lay', 'januari', 'inch', 'modest', 'temperatur', 'pull', 'next', 'beatl', 'mom', 'nois', 'pathet', 'younger', 'forev', 'would', 'spotlessli', 'crappi', 'regret', 'outdat', 'burnt', 'steakhous', 'save', 'anthoni', 'surfac', 'grab', 'unhelp', 'make', 'drip', 'particular', 'throughout', 'art', 'palm', 'nowher', 'furnitur', 'element', 'torn', 'cardio', 'request', 'blown', 'decemb', 'pad', 'altern', 'piec', 'lie', 'lit', 'question', 'poster', 'presid', 'solv', 'product', 'juli', 'video', 'san', 'swim', 'love', 'din', 'util', 'slipper', 'advertis', 'bare', 'lose', 'wellappoint', 'lake', 'leak', 'summari', 'waterfront', 'breathtak', 'fianc', 'earli', 'maid', 'afford', 'insult', 'compar', 'error', 'hi', 'acn', 'mark', 'fireplac', 'million', 'previous', 'pier', 'long', 'unit', 'dresser', 'visibl', 'nook', 'shoot', 'crisp', 'excurs', 'map', 'everywher', 'stun', 'concept', 'front', 'mignon', 'michigan', 'saturday', 'confer', 'fool', 'stale', 'mini', 'yummi', 'wardrob', 'usd', 'ration', 'cab', 'creepi', 'agre', 'lost', 'individu', 'bag', 'doormen', 'right', 'ala', 'dont', 'taxi', 'aria', 'pub', 'gotten', 'funki', 'shrug', 'happen', 'mess', 'oper', 'screen', 'far', 'david', 'plan', 'judi', 'awok', 'personnel', 'act', 'appar', 'bigger', 'got', 'call', 'wrong', 'allow', 'bought', 'hd', 'burk', 'compet', 'nice', 'file', 'happi', 'tremend', 'flawless', 'woke', 'exercis', 'broken', 'continent', 'larg', 'summer', 'lack', 'shula', 'ta', 'insect', 'latest', 'overli', 'total', 'chat', 'major', 'facil', 'regardless', 'uninterest', 'kinda', 'except', 'super', 'bucket', 'somewhat', 'insist', 'inlaw', 'bfast', 'fixtur', 'rack', 'rd', 'tight', 'endur', 'fabul', 'cub', 'hopkin', 'peel', 'refurbish', 'shuttl', 'help', 'excit', 'access', 'month', 'squar', 'truth', 'treadmil', 'monday', 'lucki', 'ritz', 'bit', 'breakfast', 'man', 'arrang', 'sole', 'mid', 'bonu', 'penninsula', 'robert', 'confus', 'monaco', 'alarm', 'overs', 'end', 'junior', 'coupl', 'normal', 'wast', 'refus', 'deal', 'premium', 'toler', 'becam', 'socal', 'intens', 'mention', 'amazingli', 'neighborhood', 'desir', 'dec', 'crumbl', 'couch', 'solid', 'upscal', 'websit', 'knew', 'switch', 'hand', 'seper', 'seem', 'fire', 'irish', 'usual', 'mean', 'soft', 'carlton', 'bite', 'upgrad', 'sat', 'toward', 'doll', 'suitcas', 'furnish', 'showerhead', 'walk', 'search', 'accustom', 'refund', 'central', 'opinion', 'menu', 'hassl', 'clair', 'read', 'trendi', 'remain', 'hous', 'attract', 'negoti', 'fit', 'wed', 'lunch', 'three', 'countertop', 'burger', 'wouldnt', 'clock', 'live', 'itch', 'intercontinent', 'sensor', 'warn', 'dog', 'gray', 'talbot', 'gourmet', 'smallest', 'william', 'sliver', 'creat', 'rough', 'tray', 'doe', 'worker', 'vega', 'charm', 'life', 'kudo', 'nightstand', 'children', 'room', 'space', 'promot', 'bang', 'bowl', 'seriou', 'unbeliev', 'getaway', 'elect', 'appreci', 'ice', 'five', 'dime', 'answer', 'layout', 'dri', 'ft', 'wet', 'palmer', 'tv', 'school', 'awhil', 'plush', 'encount', 'ear', 'blank', 'white', 'duti', 'task', 'fund', 'delici', 'often', 'brought', 'fan', 'non', 'side', 'unexpect', 'state', 'date', 'nyc', 'post', 'fight', 'bagel', 'one', 'regist', 'indiffer', 'inconveni', 'exactli', 'chair', 'fish', 'mother', 'tone', 'salad', 'financi', 'exclus', 'april', 'desk', 'anyth', 'iron', 'period', 'loud', 'genuin', 'person', 'millennium', 'report', 'band', 'trust', 'deliv', 'boutiqu', 'guy', 'till', 'accomod', 'amen', 'andrew', 'similar', 'sun', 'stand', 'otherwis', 'number', 'inept', 'unhappi', 'come', 'south', 'critic', 'despit', 'soooo', 'satisfi', 'ho', 'mistak', 'declin', 'inner', 'chain', 'internet', 'beyond', 'accept', 'faboul', 'subway', 'part', 'minut', 'badli', 'dust', 'settl', 'crash', 'apologet', 'pump', 'within', 'advic', 'greas', 'design', 'star', 'perfectli', 'dc', 'reluct', 'stroll', 'driver', 'bother', 'stage', 'wallpap', 'overcharg', 'employe', 'outdoor', 'counter', 'step', 'difficulti', 'bread', 'coffe', 'dine', 'offic', 'speedi', 'moder', 'toni', 'festiv', 'figur', 'king', 'smoke', 'correct', 'club', 'sink', 'ago', 'start', 'air', 'english', 'half', 'pretti', 'cute', 'picki', 'top', 'rather', 'apart', 'food', 'fray', 'bitten', 'wire', 'cours', 'primarili', 'go', 'gm', 'fallen', 'east', 'share', 'highlight', 'warmli', 'stretch', 'understaf', 'dark', 'cold', 'promptli', 'pain', 'royal', 'curtain', 'vari', 'duvet', 'tini', 'cut', 'correctli', 'definit', 'upper', 'notic', 'makeup', 'underground', 'green', 'glass', 'nonexist', 'orang', 'fuss', 'best', 'cake', 'sear', 'fee', 'check', 'prefer', 'almost', 'dusti', 'record', 'health', 'queen', 'teenag', 'head', 'favorit', 'conduct', 'featur', 'higher', 'ach', 'touch', 'exit', 'catch', 'coast', 'expect', 'given', 'instantli', 'experi', 'repeat', 'wacker', 'foot', 'obvious', 'uniqu', 'drain', 'wrigley', 'attempt', 'fun', 'michel', 'consider', 'instead', 'seat', 'clearli', 'found', 'prepar', 'smaller', 'capac', 'concern', 'reserv', 'neither', 'clerk', 'thought', 'chocol', 'respond', 'oven', 'vacat', 'near', 'expens', 'cost', 'hell', 'addit', 'extend', 'treelin', 'garbag', 'overpr', 'environ', 'weight', 'restur', 'onlin', 'strong', 'wow', 'gym', 'saw', 'buck', 'comment', 'pizza', 'courteou', 'absolut', 'hotelscom', 'nearbi', 'treatment', 'hang', 'surpris', 'christi', 'may', 'encourag', 'convent', 'rememb', 'citi', 'septemb', 'therefor', 'throw', 'polit', 'condescend', 'phone', 'rethink', 'av', 'dress', 'disturb', 'meal', 'buy', 'prepaid', 'classi', 'thick', 'cozi', 'fanci', 'rave', 'histor', 'receptionist', 'wise', 'sad', 'shabbi', 'inexperienc', 'quot', 'perk', 'asham', 'advantag', 'district', 'smelli', 'hardli', 'loyalti', 'shower', 'say', 'play', 'unfortun', 'goe', 'escap', 'dishwash', 'heard', 'compens', 'cash', 'pay', 'millenium', 'gorgeou', 'ruin', 'assist', 'martini', 'note', 'lumpi', 'chang', 'tip', 'let', 'function', 'inquir', 'cast', 'elsewher', 'worst', 'onto', 'prior', 'nearest', 'le', 'protestor', 'standard', 'point', 'hip', 'furiou', 'condition', 'remedi', 'spend', 'daylight', 'sak', 'adequ', 'rule', 'sofab', 'written', 'like', 'quit', 'park', 'outsid', 'highli', 'drawer', 'gross', 'ave', 'destin', 'coffeemak', 'certif', 'whole', 'last', 'skip', 'toast', 'sweet', 'st', 'ashtray', 'rise', 'reward', 'better', 'someplac', 'februari', 'refresh', 'colleg', 'nickel', 'plenti', 'ok', 'mani', 'hefti', 'ceil', 'crowd', 'bathtub', 'steer', 'mere', 'budget', 'folk', 'disapoint', 'parti', 'zone', 'inexpens', 'load', 'studi', 'expos', 'orlando', 'consid', 'prob', 'spring', 'tast', 'option', 'mood', 'memor', 'transport', 'third', 'thank', 'disconnect', 'soldier', 'stain', 'smokey', 'spoke', 'skin', 'handi', 'cheer', 'ride', 'divis', 'charg', 'chill', 'fyi', 'subpar', 'tidi', 'hard', 'bell', 'pleasur', 'umbrella', 'distinguish', 'oh', 'field', 'attitud', 'filthi', 'approxim', 'disgust', 'anxiou', 'reader', 'paid', 'weekend', 'lightbulb', 'grade', 'decept', 'full', 'bright', 'essenti', 'readi', 'valet', 'linen', 'unbeat', 'rout', 'student', 'minimum', 'warm', 'nickl', 'toilet', 'voucher', 'handicap', 'fill', 'interview', 'avenu', 'spare', 'debit', 'invit', 'broke', 'ireland', 'truli', 'countri', 'centuri', 'corner', 'ate', 'zest', 'anyon', 'rectifi', 'dumpster', 'grant', 'bodi', 'carpet', 'rare', 'upbeat', 'convert', 'issu', 'hungri', 'patron', 'trade', 'pass', 'list', 'la', 'hire', 'season', 'true', 'trump', 'alway', 'damag', 'surli', 'kinzi', 'leisur', 'action', 'speak', 'graciou', 'tabl', 'left', 'women', 'greatest', 'child', 'thursday', 'cook', 'birthday', 'pasta', 'eas', 'seven', 'bunch', 'quiet', 'pack', 'tile', 'memorabilia', 'cockroach', 'nobodi', 'fifteen', 'n', 'frustrat', 'hole', 'swissotel', 'cocktail', 'origin', 'closet', 'literatur', 'made', 'fax', 'oshea', 'wall', 'crazi', 'airport', 'affinia', 'modern', 'kicker', 'gratuiti', 'setup', 'stop', 'still', 'length', 'immacul', 'promis', 'juic', 'wa', 'restaur', 'fact', 'advert', 'leav', 'present', 'purpos', 'groceri', 'second', 'gone', 'veri', 'histori', 'advanc', 'hear', 'reciept', 'cafe', 'snow', 'came', 'handl', 'soup', 'approx', 'wait', 'cover', 'especi', 'entir', 'row', 'men', 'measur', 'concert', 'sinc', 'kimpton', 'wrap', 'idea', 'known', 'fair', 'black', 'exhaust', 'get', 'ugli', 'excel', 'trip', 'led', 'london', 'split', 'bore', 'honestli', 'lakefront', 'station', 'roomi', 'build', 'doeuvr', 'provid', 'establish', 'brown', 'bank', 'group', 'bustl', 'refriger', 'flat', 'locat', 'abov', 'perhap', 'annoy', 'die', 'sixth', 'superb', 'paper', 'unfailingli', 'fitzpatrick', 'improv'}\n",
      "Length of vocab: 2311\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"Length of vocab:\",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'wa': 1826,\n",
       "         'hotel': 1143,\n",
       "         'room': 1132,\n",
       "         'stay': 707,\n",
       "         'thi': 594,\n",
       "         'veri': 477,\n",
       "         'great': 354,\n",
       "         'nt': 337,\n",
       "         'chicago': 328,\n",
       "         'would': 327,\n",
       "         'night': 289,\n",
       "         'servic': 268,\n",
       "         'staff': 268,\n",
       "         'bed': 259,\n",
       "         'locat': 252,\n",
       "         'one': 234,\n",
       "         'us': 215,\n",
       "         'get': 208,\n",
       "         'time': 193,\n",
       "         'nice': 186,\n",
       "         'call': 180,\n",
       "         'could': 177,\n",
       "         'even': 174,\n",
       "         'day': 168,\n",
       "         'good': 164,\n",
       "         'desk': 160,\n",
       "         'onli': 160,\n",
       "         'go': 157,\n",
       "         'like': 157,\n",
       "         'check': 153,\n",
       "         'clean': 153,\n",
       "         'floor': 152,\n",
       "         'bathroom': 151,\n",
       "         'also': 144,\n",
       "         'walk': 137,\n",
       "         'help': 134,\n",
       "         'view': 133,\n",
       "         'two': 128,\n",
       "         'place': 128,\n",
       "         'back': 128,\n",
       "         'front': 127,\n",
       "         'comfort': 126,\n",
       "         'ha': 126,\n",
       "         'lobbi': 125,\n",
       "         'got': 122,\n",
       "         'book': 118,\n",
       "         'look': 115,\n",
       "         'restaur': 114,\n",
       "         'small': 112,\n",
       "         'realli': 110,\n",
       "         'never': 109,\n",
       "         'first': 109,\n",
       "         'next': 107,\n",
       "         'bar': 107,\n",
       "         'well': 105,\n",
       "         'breakfast': 104,\n",
       "         'friendli': 103,\n",
       "         'becaus': 102,\n",
       "         'use': 99,\n",
       "         'ask': 97,\n",
       "         'price': 96,\n",
       "         'recommend': 94,\n",
       "         'arriv': 94,\n",
       "         'guest': 93,\n",
       "         'love': 93,\n",
       "         'park': 93,\n",
       "         'charg': 92,\n",
       "         'better': 91,\n",
       "         'free': 89,\n",
       "         'door': 87,\n",
       "         'area': 87,\n",
       "         'busi': 87,\n",
       "         'made': 86,\n",
       "         'reserv': 86,\n",
       "         'much': 85,\n",
       "         'close': 84,\n",
       "         'work': 84,\n",
       "         'michigan': 82,\n",
       "         'citi': 80,\n",
       "         'suit': 79,\n",
       "         'take': 79,\n",
       "         'want': 79,\n",
       "         'peopl': 79,\n",
       "         'told': 77,\n",
       "         'tri': 76,\n",
       "         'experi': 76,\n",
       "         'manag': 76,\n",
       "         'rate': 75,\n",
       "         'morn': 74,\n",
       "         'say': 73,\n",
       "         'need': 73,\n",
       "         'make': 72,\n",
       "         'everyth': 72,\n",
       "         'thing': 72,\n",
       "         'ani': 72,\n",
       "         'beauti': 72,\n",
       "         'went': 71,\n",
       "         'review': 71,\n",
       "         'mani': 70,\n",
       "         'minut': 70,\n",
       "         'best': 70,\n",
       "         'expect': 70,\n",
       "         'weekend': 69,\n",
       "         'larg': 69,\n",
       "         'water': 69,\n",
       "         'wonder': 68,\n",
       "         'return': 68,\n",
       "         'shop': 68,\n",
       "         'travel': 67,\n",
       "         'request': 66,\n",
       "         'befor': 66,\n",
       "         'th': 66,\n",
       "         'elev': 65,\n",
       "         'street': 65,\n",
       "         'hour': 65,\n",
       "         'right': 64,\n",
       "         'shower': 64,\n",
       "         'open': 64,\n",
       "         'coffe': 64,\n",
       "         'excel': 64,\n",
       "         'wait': 63,\n",
       "         'anoth': 63,\n",
       "         'trip': 63,\n",
       "         'found': 63,\n",
       "         'problem': 61,\n",
       "         'find': 61,\n",
       "         'phone': 61,\n",
       "         'year': 61,\n",
       "         'said': 61,\n",
       "         'feel': 60,\n",
       "         'food': 60,\n",
       "         'come': 60,\n",
       "         'star': 59,\n",
       "         'everi': 59,\n",
       "         'wall': 58,\n",
       "         'think': 58,\n",
       "         'old': 58,\n",
       "         'away': 56,\n",
       "         'way': 56,\n",
       "         'offer': 56,\n",
       "         'came': 55,\n",
       "         'internet': 55,\n",
       "         'pay': 55,\n",
       "         'though': 54,\n",
       "         'visit': 54,\n",
       "         'last': 54,\n",
       "         'window': 53,\n",
       "         'upgrad': 53,\n",
       "         'definit': 53,\n",
       "         'lot': 52,\n",
       "         'concierg': 52,\n",
       "         'disappoint': 51,\n",
       "         'littl': 51,\n",
       "         'quit': 51,\n",
       "         'seem': 50,\n",
       "         'hilton': 50,\n",
       "         'see': 50,\n",
       "         'mile': 50,\n",
       "         'took': 49,\n",
       "         'still': 49,\n",
       "         'person': 49,\n",
       "         'dure': 48,\n",
       "         'deal': 48,\n",
       "         'enjoy': 48,\n",
       "         'decor': 48,\n",
       "         'hard': 47,\n",
       "         'tv': 47,\n",
       "         'around': 47,\n",
       "         'left': 47,\n",
       "         'sever': 47,\n",
       "         'pool': 47,\n",
       "         'size': 45,\n",
       "         'put': 45,\n",
       "         'bad': 45,\n",
       "         'custom': 45,\n",
       "         'noth': 45,\n",
       "         'king': 45,\n",
       "         'differ': 44,\n",
       "         'block': 44,\n",
       "         'gave': 44,\n",
       "         'downtown': 44,\n",
       "         'week': 44,\n",
       "         'quiet': 44,\n",
       "         'paid': 44,\n",
       "         'checkin': 44,\n",
       "         'tower': 44,\n",
       "         'top': 43,\n",
       "         'big': 43,\n",
       "         'final': 43,\n",
       "         'know': 43,\n",
       "         'river': 43,\n",
       "         'pm': 42,\n",
       "         'rude': 42,\n",
       "         'confer': 42,\n",
       "         'new': 42,\n",
       "         'alway': 41,\n",
       "         'bit': 41,\n",
       "         'extrem': 41,\n",
       "         'worth': 41,\n",
       "         'drink': 41,\n",
       "         'enough': 40,\n",
       "         'etc': 40,\n",
       "         'famili': 40,\n",
       "         'sinc': 40,\n",
       "         'long': 39,\n",
       "         'ave': 39,\n",
       "         'car': 39,\n",
       "         'wife': 39,\n",
       "         'end': 39,\n",
       "         'second': 39,\n",
       "         'perfect': 39,\n",
       "         'spaciou': 38,\n",
       "         'upon': 38,\n",
       "         'ever': 38,\n",
       "         'properti': 38,\n",
       "         'howev': 38,\n",
       "         'abl': 38,\n",
       "         'husband': 37,\n",
       "         'within': 37,\n",
       "         'extra': 37,\n",
       "         'dinner': 37,\n",
       "         'avail': 37,\n",
       "         'high': 37,\n",
       "         'wine': 36,\n",
       "         'home': 36,\n",
       "         'line': 36,\n",
       "         'friend': 36,\n",
       "         'includ': 36,\n",
       "         'chang': 35,\n",
       "         'someth': 35,\n",
       "         'sure': 35,\n",
       "         'overal': 35,\n",
       "         'felt': 35,\n",
       "         'give': 35,\n",
       "         'build': 35,\n",
       "         'anyth': 34,\n",
       "         'huge': 34,\n",
       "         'hi': 34,\n",
       "         'amen': 34,\n",
       "         'part': 34,\n",
       "         'without': 34,\n",
       "         'renov': 34,\n",
       "         'omni': 34,\n",
       "         'tini': 34,\n",
       "         'access': 34,\n",
       "         'sleep': 33,\n",
       "         'order': 33,\n",
       "         'rock': 33,\n",
       "         'pillow': 33,\n",
       "         'per': 33,\n",
       "         'leav': 33,\n",
       "         'gener': 33,\n",
       "         'let': 33,\n",
       "         'qualiti': 33,\n",
       "         'money': 33,\n",
       "         'full': 33,\n",
       "         'impress': 33,\n",
       "         'housekeep': 33,\n",
       "         'read': 33,\n",
       "         'cool': 32,\n",
       "         'modern': 32,\n",
       "         'recent': 32,\n",
       "         'thank': 32,\n",
       "         'hous': 32,\n",
       "         'hyatt': 32,\n",
       "         'complain': 31,\n",
       "         'card': 31,\n",
       "         'absolut': 31,\n",
       "         'ambassador': 31,\n",
       "         'show': 31,\n",
       "         'pricelin': 31,\n",
       "         'expens': 31,\n",
       "         'provid': 31,\n",
       "         'three': 31,\n",
       "         'distanc': 31,\n",
       "         'eat': 31,\n",
       "         'fantast': 31,\n",
       "         'nois': 30,\n",
       "         'doe': 30,\n",
       "         'side': 30,\n",
       "         'hear': 30,\n",
       "         'late': 30,\n",
       "         'lake': 30,\n",
       "         'thought': 30,\n",
       "         'navi': 30,\n",
       "         'pier': 30,\n",
       "         'issu': 30,\n",
       "         'point': 30,\n",
       "         'recept': 30,\n",
       "         'may': 30,\n",
       "         'actual': 30,\n",
       "         'everyon': 30,\n",
       "         'magnific': 30,\n",
       "         'complaint': 29,\n",
       "         'sit': 29,\n",
       "         'dirti': 29,\n",
       "         'towel': 29,\n",
       "         'construct': 29,\n",
       "         'valet': 29,\n",
       "         'almost': 29,\n",
       "         'especi': 29,\n",
       "         'bottl': 29,\n",
       "         'ca': 29,\n",
       "         'employe': 29,\n",
       "         'although': 29,\n",
       "         'els': 29,\n",
       "         'earli': 29,\n",
       "         'talbott': 28,\n",
       "         'whi': 28,\n",
       "         'websit': 28,\n",
       "         'least': 28,\n",
       "         'less': 28,\n",
       "         'welcom': 28,\n",
       "         'tub': 28,\n",
       "         'happen': 28,\n",
       "         'special': 28,\n",
       "         'cost': 28,\n",
       "         'highli': 28,\n",
       "         'live': 28,\n",
       "         'closet': 28,\n",
       "         'light': 28,\n",
       "         'care': 28,\n",
       "         'someon': 27,\n",
       "         'sheet': 27,\n",
       "         'member': 27,\n",
       "         'avenu': 27,\n",
       "         'cab': 27,\n",
       "         'state': 27,\n",
       "         'conrad': 27,\n",
       "         'start': 27,\n",
       "         'abov': 27,\n",
       "         'wifi': 27,\n",
       "         'deliv': 27,\n",
       "         'spent': 27,\n",
       "         'receiv': 26,\n",
       "         'jame': 26,\n",
       "         'name': 26,\n",
       "         'fairmont': 26,\n",
       "         'tell': 26,\n",
       "         'amalfi': 26,\n",
       "         'coupl': 25,\n",
       "         'complet': 25,\n",
       "         'reason': 25,\n",
       "         'given': 25,\n",
       "         'train': 25,\n",
       "         'turn': 25,\n",
       "         'touch': 25,\n",
       "         'mention': 25,\n",
       "         'club': 25,\n",
       "         'easi': 25,\n",
       "         'anyon': 25,\n",
       "         'corner': 25,\n",
       "         'instead': 25,\n",
       "         'decid': 24,\n",
       "         'far': 24,\n",
       "         'serv': 24,\n",
       "         'move': 24,\n",
       "         'stop': 24,\n",
       "         'pleas': 24,\n",
       "         'cover': 24,\n",
       "         'air': 24,\n",
       "         'monaco': 24,\n",
       "         'hot': 24,\n",
       "         'space': 24,\n",
       "         'attend': 24,\n",
       "         'hallway': 24,\n",
       "         'done': 24,\n",
       "         'allegro': 24,\n",
       "         'toilet': 24,\n",
       "         'fact': 24,\n",
       "         'doubl': 24,\n",
       "         'east': 23,\n",
       "         'onc': 23,\n",
       "         'later': 23,\n",
       "         'must': 23,\n",
       "         'conveni': 23,\n",
       "         'saw': 23,\n",
       "         'swissotel': 23,\n",
       "         'unfortun': 23,\n",
       "         'chair': 23,\n",
       "         'across': 23,\n",
       "         'incred': 23,\n",
       "         'pretti': 23,\n",
       "         'readi': 23,\n",
       "         'town': 23,\n",
       "         'short': 23,\n",
       "         'treat': 23,\n",
       "         'confirm': 23,\n",
       "         'screen': 22,\n",
       "         'near': 22,\n",
       "         'choos': 22,\n",
       "         'notic': 22,\n",
       "         'immedi': 22,\n",
       "         'kimpton': 22,\n",
       "         'bill': 22,\n",
       "         'choic': 22,\n",
       "         'greet': 22,\n",
       "         'kind': 22,\n",
       "         'furnitur': 22,\n",
       "         'heard': 22,\n",
       "         'complimentari': 22,\n",
       "         'usual': 22,\n",
       "         'surpris': 22,\n",
       "         'fit': 22,\n",
       "         'amaz': 22,\n",
       "         'smoke': 22,\n",
       "         'ye': 21,\n",
       "         'carpet': 21,\n",
       "         'ok': 21,\n",
       "         'warm': 21,\n",
       "         'separ': 21,\n",
       "         'set': 21,\n",
       "         'key': 21,\n",
       "         'credit': 21,\n",
       "         'knickerbock': 21,\n",
       "         'base': 21,\n",
       "         'art': 21,\n",
       "         'secur': 21,\n",
       "         'directli': 21,\n",
       "         'cancel': 21,\n",
       "         'four': 20,\n",
       "         'might': 20,\n",
       "         'pleasant': 20,\n",
       "         'checkout': 20,\n",
       "         'bug': 20,\n",
       "         'daughter': 20,\n",
       "         'buffet': 20,\n",
       "         'sheraton': 20,\n",
       "         'palmer': 20,\n",
       "         'comfi': 20,\n",
       "         'miss': 20,\n",
       "         'intercontinent': 20,\n",
       "         'broken': 20,\n",
       "         'lack': 20,\n",
       "         'center': 20,\n",
       "         'simpli': 19,\n",
       "         'sound': 19,\n",
       "         'loop': 19,\n",
       "         'sign': 19,\n",
       "         'past': 19,\n",
       "         'dark': 19,\n",
       "         'mayb': 19,\n",
       "         'option': 19,\n",
       "         'inform': 19,\n",
       "         'happi': 19,\n",
       "         'fabul': 19,\n",
       "         'entir': 19,\n",
       "         'gym': 19,\n",
       "         'wed': 19,\n",
       "         'either': 19,\n",
       "         'addit': 19,\n",
       "         'airport': 19,\n",
       "         'despit': 19,\n",
       "         'bath': 18,\n",
       "         'doorman': 18,\n",
       "         'inn': 18,\n",
       "         'keep': 18,\n",
       "         'head': 18,\n",
       "         'neg': 18,\n",
       "         'suggest': 18,\n",
       "         'valu': 18,\n",
       "         'fine': 18,\n",
       "         'standard': 18,\n",
       "         'clerk': 18,\n",
       "         'date': 18,\n",
       "         'alreadi': 18,\n",
       "         'north': 18,\n",
       "         'cold': 18,\n",
       "         'outsid': 18,\n",
       "         'meet': 18,\n",
       "         'system': 17,\n",
       "         'glass': 17,\n",
       "         'plan': 17,\n",
       "         'spend': 17,\n",
       "         'pictur': 17,\n",
       "         'major': 17,\n",
       "         'site': 17,\n",
       "         'replac': 17,\n",
       "         'probabl': 17,\n",
       "         'millenium': 17,\n",
       "         'appear': 17,\n",
       "         'bring': 17,\n",
       "         'previou': 17,\n",
       "         'note': 17,\n",
       "         'bell': 17,\n",
       "         'mistak': 17,\n",
       "         'yet': 17,\n",
       "         'situat': 17,\n",
       "         'consid': 17,\n",
       "         'oh': 17,\n",
       "         'maid': 17,\n",
       "         'suppos': 17,\n",
       "         'frequent': 17,\n",
       "         'compar': 17,\n",
       "         'paper': 17,\n",
       "         'girl': 17,\n",
       "         'honor': 16,\n",
       "         'prefer': 16,\n",
       "         'mini': 16,\n",
       "         'fun': 16,\n",
       "         'boutiqu': 16,\n",
       "         'bedroom': 16,\n",
       "         'tast': 16,\n",
       "         'due': 16,\n",
       "         'stain': 16,\n",
       "         'decent': 16,\n",
       "         'guy': 16,\n",
       "         'half': 16,\n",
       "         'lost': 16,\n",
       "         'futur': 16,\n",
       "         'promis': 16,\n",
       "         'compani': 16,\n",
       "         'fridg': 16,\n",
       "         'plenti': 16,\n",
       "         'doormen': 16,\n",
       "         'nd': 16,\n",
       "         'whole': 16,\n",
       "         'throughout': 16,\n",
       "         'bare': 16,\n",
       "         'loud': 16,\n",
       "         'annoy': 16,\n",
       "         'answer': 16,\n",
       "         'run': 16,\n",
       "         'sofitel': 16,\n",
       "         'basic': 16,\n",
       "         'month': 15,\n",
       "         'total': 15,\n",
       "         'poor': 15,\n",
       "         'tabl': 15,\n",
       "         'super': 15,\n",
       "         'music': 15,\n",
       "         'furnish': 15,\n",
       "         'cours': 15,\n",
       "         'convent': 15,\n",
       "         'loung': 15,\n",
       "         'attent': 15,\n",
       "         'knew': 15,\n",
       "         'sofa': 15,\n",
       "         'minibar': 15,\n",
       "         'forward': 15,\n",
       "         'attract': 15,\n",
       "         'except': 15,\n",
       "         'along': 15,\n",
       "         'watch': 15,\n",
       "         'hand': 15,\n",
       "         'older': 15,\n",
       "         'apolog': 15,\n",
       "         'plu': 15,\n",
       "         'min': 15,\n",
       "         'flat': 15,\n",
       "         'low': 15,\n",
       "         'smell': 15,\n",
       "         'fail': 15,\n",
       "         'allow': 15,\n",
       "         'onlin': 15,\n",
       "         'guess': 14,\n",
       "         'worst': 14,\n",
       "         'receptionist': 14,\n",
       "         'main': 14,\n",
       "         'insid': 14,\n",
       "         'tip': 14,\n",
       "         'sunday': 14,\n",
       "         'email': 14,\n",
       "         'fee': 14,\n",
       "         'beyond': 14,\n",
       "         'slow': 14,\n",
       "         'superb': 14,\n",
       "         'nearbi': 14,\n",
       "         'pick': 14,\n",
       "         'face': 14,\n",
       "         'prior': 14,\n",
       "         'pass': 14,\n",
       "         'updat': 14,\n",
       "         'uncomfort': 14,\n",
       "         'ride': 14,\n",
       "         'bag': 14,\n",
       "         'store': 14,\n",
       "         'brought': 14,\n",
       "         'rd': 14,\n",
       "         'parti': 14,\n",
       "         'smile': 14,\n",
       "         'hope': 14,\n",
       "         'interest': 14,\n",
       "         'slept': 14,\n",
       "         'histor': 14,\n",
       "         'talk': 14,\n",
       "         'posit': 14,\n",
       "         'fresh': 14,\n",
       "         'shampoo': 14,\n",
       "         'class': 14,\n",
       "         'chose': 14,\n",
       "         'son': 14,\n",
       "         'averag': 14,\n",
       "         'case': 14,\n",
       "         'level': 14,\n",
       "         'tire': 14,\n",
       "         'believ': 13,\n",
       "         'roll': 13,\n",
       "         'luxuri': 13,\n",
       "         'pump': 13,\n",
       "         'easili': 13,\n",
       "         'larger': 13,\n",
       "         'blanket': 13,\n",
       "         'kid': 13,\n",
       "         'possibl': 13,\n",
       "         'mean': 13,\n",
       "         'red': 13,\n",
       "         'appreci': 13,\n",
       "         'ridicul': 13,\n",
       "         'rest': 13,\n",
       "         'downstair': 13,\n",
       "         'dollar': 13,\n",
       "         'noisi': 13,\n",
       "         'machin': 13,\n",
       "         'clearli': 13,\n",
       "         'account': 13,\n",
       "         'entranc': 13,\n",
       "         'mind': 13,\n",
       "         'job': 13,\n",
       "         'send': 13,\n",
       "         'fix': 13,\n",
       "         'kept': 13,\n",
       "         'taxi': 13,\n",
       "         'type': 13,\n",
       "         'attach': 13,\n",
       "         'public': 13,\n",
       "         'ad': 13,\n",
       "         'arrang': 13,\n",
       "         'tour': 13,\n",
       "         'pull': 13,\n",
       "         'nonsmok': 13,\n",
       "         'favorit': 12,\n",
       "         'rather': 12,\n",
       "         'normal': 12,\n",
       "         'degre': 12,\n",
       "         'eleg': 12,\n",
       "         'hold': 12,\n",
       "         'terribl': 12,\n",
       "         'garag': 12,\n",
       "         'event': 12,\n",
       "         'quick': 12,\n",
       "         'understand': 12,\n",
       "         'sink': 12,\n",
       "         'station': 12,\n",
       "         'seat': 12,\n",
       "         'board': 12,\n",
       "         'hesit': 12,\n",
       "         'getaway': 12,\n",
       "         'beat': 12,\n",
       "         'luggag': 12,\n",
       "         'certainli': 12,\n",
       "         'taken': 12,\n",
       "         'question': 12,\n",
       "         'neighborhood': 12,\n",
       "         'group': 12,\n",
       "         'central': 12,\n",
       "         'cheap': 12,\n",
       "         'nobodi': 12,\n",
       "         'museum': 12,\n",
       "         'twice': 12,\n",
       "         'hall': 12,\n",
       "         'wrong': 12,\n",
       "         'otherwis': 12,\n",
       "         'truli': 12,\n",
       "         'gift': 12,\n",
       "         'stand': 12,\n",
       "         'linen': 12,\n",
       "         'packag': 12,\n",
       "         'perhap': 12,\n",
       "         'polici': 12,\n",
       "         'speak': 11,\n",
       "         'gone': 11,\n",
       "         'design': 11,\n",
       "         'anywher': 11,\n",
       "         'charm': 11,\n",
       "         'chain': 11,\n",
       "         'cozi': 11,\n",
       "         'holiday': 11,\n",
       "         'woke': 11,\n",
       "         'oper': 11,\n",
       "         'nicer': 11,\n",
       "         'none': 11,\n",
       "         'report': 11,\n",
       "         'claim': 11,\n",
       "         'continu': 11,\n",
       "         'queen': 11,\n",
       "         'ate': 11,\n",
       "         'awesom': 11,\n",
       "         'dine': 11,\n",
       "         'comput': 11,\n",
       "         'overpr': 11,\n",
       "         'thin': 11,\n",
       "         'write': 11,\n",
       "         'behind': 11,\n",
       "         'item': 11,\n",
       "         'safe': 11,\n",
       "         'polit': 11,\n",
       "         'toiletri': 11,\n",
       "         'connect': 11,\n",
       "         'stuff': 11,\n",
       "         'swim': 11,\n",
       "         'rush': 11,\n",
       "         'transport': 11,\n",
       "         'discov': 11,\n",
       "         'follow': 11,\n",
       "         'season': 11,\n",
       "         'anniversari': 11,\n",
       "         'kitchen': 11,\n",
       "         'seen': 11,\n",
       "         'st': 11,\n",
       "         'wo': 11,\n",
       "         'number': 11,\n",
       "         'terrif': 11,\n",
       "         'offic': 11,\n",
       "         'imagin': 11,\n",
       "         'earlier': 11,\n",
       "         'relax': 11,\n",
       "         'fan': 11,\n",
       "         'correct': 11,\n",
       "         'menu': 11,\n",
       "         'soap': 11,\n",
       "         'lower': 10,\n",
       "         'horribl': 10,\n",
       "         'switch': 10,\n",
       "         'appoint': 10,\n",
       "         'fixtur': 10,\n",
       "         'teenag': 10,\n",
       "         'world': 10,\n",
       "         'profession': 10,\n",
       "         'style': 10,\n",
       "         'word': 10,\n",
       "         'five': 10,\n",
       "         'direct': 10,\n",
       "         'paint': 10,\n",
       "         'elsewher': 10,\n",
       "         'saturday': 10,\n",
       "         'via': 10,\n",
       "         'effici': 10,\n",
       "         'maker': 10,\n",
       "         'slightli': 10,\n",
       "         'met': 10,\n",
       "         'assign': 10,\n",
       "         'explain': 10,\n",
       "         'hair': 10,\n",
       "         'couch': 10,\n",
       "         'overlook': 10,\n",
       "         'meal': 10,\n",
       "         'ice': 10,\n",
       "         'regular': 10,\n",
       "         'accommod': 10,\n",
       "         'drive': 10,\n",
       "         'share': 10,\n",
       "         'figur': 10,\n",
       "         'spa': 10,\n",
       "         'appar': 10,\n",
       "         'juli': 10,\n",
       "         'execut': 10,\n",
       "         'young': 10,\n",
       "         'cut': 10,\n",
       "         'mall': 10,\n",
       "         'higher': 10,\n",
       "         'man': 10,\n",
       "         'somewher': 10,\n",
       "         'grant': 10,\n",
       "         'bellman': 10,\n",
       "         'workout': 10,\n",
       "         'contact': 10,\n",
       "         'institut': 10,\n",
       "         'l': 10,\n",
       "         'hospit': 10,\n",
       "         'quickli': 10,\n",
       "         'difficult': 10,\n",
       "         'advanc': 9,\n",
       "         'awar': 9,\n",
       "         'list': 9,\n",
       "         'thru': 9,\n",
       "         'program': 9,\n",
       "         'post': 9,\n",
       "         'cloth': 9,\n",
       "         'handl': 9,\n",
       "         'wors': 9,\n",
       "         'fault': 9,\n",
       "         'flight': 9,\n",
       "         'shoe': 9,\n",
       "         'comment': 9,\n",
       "         'membership': 9,\n",
       "         'facil': 9,\n",
       "         'ie': 9,\n",
       "         'snack': 9,\n",
       "         'neighbor': 9,\n",
       "         'ago': 9,\n",
       "         'pro': 9,\n",
       "         'hang': 9,\n",
       "         'bother': 9,\n",
       "         'pleasur': 9,\n",
       "         'didnt': 9,\n",
       "         'w': 9,\n",
       "         'men': 9,\n",
       "         'heat': 9,\n",
       "         'save': 9,\n",
       "         'respons': 9,\n",
       "         'inconveni': 9,\n",
       "         'condition': 9,\n",
       "         'select': 9,\n",
       "         'white': 9,\n",
       "         'iron': 9,\n",
       "         'excit': 9,\n",
       "         'wish': 9,\n",
       "         'cramp': 9,\n",
       "         'simpl': 9,\n",
       "         'longer': 9,\n",
       "         'stair': 9,\n",
       "         'sent': 9,\n",
       "         'encount': 9,\n",
       "         'everywher': 9,\n",
       "         'mainten': 9,\n",
       "         'third': 9,\n",
       "         'spot': 9,\n",
       "         'birthday': 8,\n",
       "         'photo': 8,\n",
       "         'classic': 8,\n",
       "         'waiter': 8,\n",
       "         'bite': 8,\n",
       "         'enter': 8,\n",
       "         'bonu': 8,\n",
       "         'cup': 8,\n",
       "         'tax': 8,\n",
       "         'sort': 8,\n",
       "         'condit': 8,\n",
       "         'particularli': 8,\n",
       "         'assist': 8,\n",
       "         'courteou': 8,\n",
       "         'rememb': 8,\n",
       "         'minor': 8,\n",
       "         'featur': 8,\n",
       "         'print': 8,\n",
       "         'frustrat': 8,\n",
       "         'worn': 8,\n",
       "         'starbuck': 8,\n",
       "         'millennium': 8,\n",
       "         'june': 8,\n",
       "         'ohar': 8,\n",
       "         'luck': 8,\n",
       "         'notch': 8,\n",
       "         'experienc': 8,\n",
       "         'chees': 8,\n",
       "         'gorgeou': 8,\n",
       "         'defin': 8,\n",
       "         'mirror': 8,\n",
       "         'smaller': 8,\n",
       "         'flower': 8,\n",
       "         'juic': 8,\n",
       "         'tea': 8,\n",
       "         'bottom': 8,\n",
       "         'somewhat': 8,\n",
       "         'delici': 8,\n",
       "         'muffin': 8,\n",
       "         'lock': 8,\n",
       "         'superior': 8,\n",
       "         'break': 8,\n",
       "         'woman': 8,\n",
       "         'unless': 8,\n",
       "         'south': 8,\n",
       "         'traffic': 8,\n",
       "         'accomod': 8,\n",
       "         'el': 8,\n",
       "         'peninsula': 8,\n",
       "         'obvious': 8,\n",
       "         'pack': 8,\n",
       "         'mattress': 8,\n",
       "         'ipod': 8,\n",
       "         'life': 8,\n",
       "         'summer': 8,\n",
       "         'record': 8,\n",
       "         'centr': 8,\n",
       "         'advertis': 8,\n",
       "         'fell': 8,\n",
       "         'transfer': 8,\n",
       "         'fast': 8,\n",
       "         'exactli': 8,\n",
       "         'bright': 8,\n",
       "         'brick': 7,\n",
       "         'robe': 7,\n",
       "         'concern': 7,\n",
       "         'delight': 7,\n",
       "         'wake': 7,\n",
       "         'mold': 7,\n",
       "         'roof': 7,\n",
       "         'age': 7,\n",
       "         'add': 7,\n",
       "         'depart': 7,\n",
       "         'stuck': 7,\n",
       "         'toward': 7,\n",
       "         'wireless': 7,\n",
       "         'channel': 7,\n",
       "         'brand': 7,\n",
       "         'hancock': 7,\n",
       "         'subway': 7,\n",
       "         'atmospher': 7,\n",
       "         'similar': 7,\n",
       "         'upscal': 7,\n",
       "         'activ': 7,\n",
       "         'serious': 7,\n",
       "         'ladi': 7,\n",
       "         'con': 7,\n",
       "         'cafe': 7,\n",
       "         'crowd': 7,\n",
       "         'lunch': 7,\n",
       "         'hotwir': 7,\n",
       "         'moment': 7,\n",
       "         'plasma': 7,\n",
       "         'hr': 7,\n",
       "         'apart': 7,\n",
       "         'mediocr': 7,\n",
       "         'curtain': 7,\n",
       "         'boy': 7,\n",
       "         'disgust': 7,\n",
       "         'girlfriend': 7,\n",
       "         'troubl': 7,\n",
       "         'agre': 7,\n",
       "         'bartend': 7,\n",
       "         'blue': 7,\n",
       "         'shuttl': 7,\n",
       "         'requir': 7,\n",
       "         'regist': 7,\n",
       "         'function': 7,\n",
       "         'fruit': 7,\n",
       "         'sweet': 7,\n",
       "         'cake': 7,\n",
       "         'european': 7,\n",
       "         'drake': 7,\n",
       "         'soon': 7,\n",
       "         'peel': 7,\n",
       "         'theater': 7,\n",
       "         'bore': 7,\n",
       "         'real': 7,\n",
       "         'vacat': 7,\n",
       "         'fish': 7,\n",
       "         'matter': 7,\n",
       "         'confus': 7,\n",
       "         'current': 7,\n",
       "         'remind': 7,\n",
       "         'marriott': 7,\n",
       "         'westin': 7,\n",
       "         'disturb': 7,\n",
       "         'nearli': 7,\n",
       "         'regenc': 7,\n",
       "         'purchas': 7,\n",
       "         'gold': 7,\n",
       "         'particular': 7,\n",
       "         'middl': 7,\n",
       "         'duvet': 7,\n",
       "         'rang': 7,\n",
       "         'remov': 7,\n",
       "         'learn': 7,\n",
       "         'yeah': 7,\n",
       "         'flush': 7,\n",
       "         'onto': 7,\n",
       "         'premium': 7,\n",
       "         'foot': 7,\n",
       "         'mess': 7,\n",
       "         'ticket': 7,\n",
       "         'upper': 6,\n",
       "         'chic': 6,\n",
       "         'trendi': 6,\n",
       "         'compens': 6,\n",
       "         'theme': 6,\n",
       "         'overnight': 6,\n",
       "         'daili': 6,\n",
       "         'wear': 6,\n",
       "         'fare': 6,\n",
       "         'import': 6,\n",
       "         'eventu': 6,\n",
       "         'attitud': 6,\n",
       "         'file': 6,\n",
       "         'built': 6,\n",
       "         'leisur': 6,\n",
       "         'improv': 6,\n",
       "         'adult': 6,\n",
       "         'prepaid': 6,\n",
       "         'filthi': 6,\n",
       "         'fall': 6,\n",
       "         'bargain': 6,\n",
       "         'bu': 6,\n",
       "         'pet': 6,\n",
       "         'scene': 6,\n",
       "         'feet': 6,\n",
       "         'spread': 6,\n",
       "         'bank': 6,\n",
       "         'corpor': 6,\n",
       "         'step': 6,\n",
       "         'dessert': 6,\n",
       "         'rain': 6,\n",
       "         'hole': 6,\n",
       "         'realiz': 6,\n",
       "         'control': 6,\n",
       "         'opinion': 6,\n",
       "         'redeem': 6,\n",
       "         'cheer': 6,\n",
       "         'beer': 6,\n",
       "         ...})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing unknown words with a token <unk>\n",
    "def replace_unk(sentences, vocab=vocab):\n",
    "    \n",
    "    sentences = preprocessing(sentences)\n",
    "    sentences = sentences.lower().split()\n",
    "    \n",
    "    x = [word if word in vocab else \"<unk>\" for word in sentences]\n",
    "    x = ' '.join(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love brick wall alleyway thi view ask room face river get room face brick wall realli piss great review wa expect better befor came stay hyatt nyc wa awesom wa noth hotel blew away wine hour wa ok wa hope would someth better food guess whi wine hour order room servic one night wa nt realli anywher eat eat bed watch tv thi wa first time come chicago think last thoroughli disappoint\n",
      "love brick wall <unk> thi view ask room face river get room face brick wall realli <unk> great review wa expect better befor came stay hyatt nyc wa awesom wa noth hotel blew away wine hour wa ok wa hope would someth better food guess whi wine hour order room servic one night wa nt realli <unk> eat eat bed watch tv thi wa first time come chicago think last thoroughli disappoint\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "new = replace_unk(clean_test_sent, vocab)\n",
    "print(clean_test_sent)\n",
    "print(new)\n",
    "print(new.count('<unk>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I stayed for four nights while attending a con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we love the location and proximity to everythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to issue a travel-warning to folks who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just got back from three nights at the Knicker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My family and I stayed at this hotel during an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>My husband and I were very excited to be stayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Had a week long stay at the Hilton on south Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>If you love Brick Walls and Alleyways , then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Booked a room w/ a queen bed for 2 nights for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stayed there three nights from 4/17/09 through...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews\n",
       "0   I stayed for four nights while attending a con...\n",
       "1   we love the location and proximity to everythi...\n",
       "2   I want to issue a travel-warning to folks who ...\n",
       "3   Just got back from three nights at the Knicker...\n",
       "4   My family and I stayed at this hotel during an...\n",
       "..                                                ...\n",
       "65  My husband and I were very excited to be stayi...\n",
       "66  Had a week long stay at the Hilton on south Mi...\n",
       "67  If you love Brick Walls and Alleyways , then t...\n",
       "68  Booked a room w/ a queen bed for 2 nights for ...\n",
       "69  Stayed there three nights from 4/17/09 through...\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Great , awesome service . Seriously , the peop...</td>\n",
       "      <td>great awesom servic serious peopl amaz nice ba...</td>\n",
       "      <td>great awesom servic seriou peopl amaz nice bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Beautifully appointed , professionally staffed...</td>\n",
       "      <td>beauti appoint profession staf comfort wellloc...</td>\n",
       "      <td>beauti appoint &lt;unk&gt; staf comfort &lt;unk&gt; eleg w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>My wife and I stayed here for a long weekend a...</td>\n",
       "      <td>wife stay long weekend wa great checkin staff ...</td>\n",
       "      <td>wife stay long weekend wa great checkin staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>We stayed 2 nights over spring break in what w...</td>\n",
       "      <td>stay night spring break wa call jr suit resemb...</td>\n",
       "      <td>stay night spring break wa call &lt;unk&gt; suit &lt;un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>My daughter and I were in Chicago for one nigh...</td>\n",
       "      <td>daughter chicago one night attend threeday con...</td>\n",
       "      <td>daughter chicago one night attend &lt;unk&gt; confer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  \\\n",
       "29  Great , awesome service . Seriously , the peop...   \n",
       "25  Beautifully appointed , professionally staffed...   \n",
       "38  My wife and I stayed here for a long weekend a...   \n",
       "53  We stayed 2 nights over spring break in what w...   \n",
       "26  My daughter and I were in Chicago for one nigh...   \n",
       "\n",
       "                                                clean  \\\n",
       "29  great awesom servic serious peopl amaz nice ba...   \n",
       "25  beauti appoint profession staf comfort wellloc...   \n",
       "38  wife stay long weekend wa great checkin staff ...   \n",
       "53  stay night spring break wa call jr suit resemb...   \n",
       "26  daughter chicago one night attend threeday con...   \n",
       "\n",
       "                                             filtered  \n",
       "29  great awesom servic seriou peopl amaz nice bar...  \n",
       "25  beauti appoint <unk> staf comfort <unk> eleg w...  \n",
       "38  wife stay long weekend wa great checkin staff ...  \n",
       "53  stay night spring break wa call <unk> suit <un...  \n",
       "26  daughter chicago one night attend <unk> confer...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['clean'] = df_test['reviews'].apply(lambda x: preprocessing(x))\n",
    "df_test['filtered'] = df_test['clean'].apply(lambda x: replace_unk(x,vocab))\n",
    "df_test.sample(5) #test data with all unknown words handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram probabilities: {'book': 0.0345, 'two': 0.023, 'room': 0.0345, 'four': 0.0115, 'month': 0.0115, 'advanc': 0.0115, 'talbott': 0.0115, 'place': 0.0345, 'top': 0.023, 'floor': 0.0805, 'next': 0.0115, 'elev': 0.023, 'use': 0.023, 'night': 0.0115, 'long': 0.0115, 'speak': 0.0115, 'front': 0.0115, 'desk': 0.0115, 'wa': 0.0115, 'told': 0.023, 'simpli': 0.023, 'honor': 0.0115, 'request': 0.0575, 'upper': 0.023, 'better': 0.0115, 'view': 0.0115, 'look': 0.0115, 'brick': 0.0115, 'wall': 0.0115, 'get': 0.0115, 'sleep': 0.0115, 'also': 0.0115, 'receiv': 0.0115, 'complaint': 0.0115, 'befor': 0.0115, 'guest': 0.023, 'th': 0.0115, 'awar': 0.0115, 'nois': 0.0115, 'problem': 0.0115, 'whi': 0.0115, 'us': 0.0115, 'thi': 0.0345, 'hotel': 0.0115, 'total': 0.0115, 'doe': 0.0115, 'constitut': 0.0115, 'someon': 0.0115, 'justifi': 0.0115, 'decid': 0.0115, 'stay': 0.0115, 'lower': 0.0115, 'away': 0.0115, 'spoke': 0.0115, 'length': 0.0115, 'prefer': 0.0115, 'poor': 0.0115, 'treatment': 0.0115, 'believ': 0.0115, 'would': 0.0115, 'complain': 0.0115}\n",
      "Bigram probabilities: {'book': {'two': 0.6667, 'request': 0.3333}, 'two': {'room': 1.0}, 'room': {'four': 0.3333, 'lower': 0.3333, 'prefer': 0.3333}, 'four': {'month': 1.0}, 'month': {'advanc': 1.0}, 'advanc': {'talbott': 1.0}, 'talbott': {'place': 1.0}, 'place': {'top': 0.3333, 'us': 0.3333, 'someon': 0.3333}, 'top': {'floor': 1.0}, 'floor': {'next': 0.1429, 'request': 0.1429, 'awar': 0.1429, 'hotel': 0.1429, 'doe': 0.1429, 'use': 0.1429, 'away': 0.1429}, 'next': {'elev': 1.0}, 'elev': {'use': 0.5, 'spoke': 0.5}, 'use': {'night': 0.5, 'request': 0.5}, 'night': {'long': 1.0}, 'long': {'speak': 1.0}, 'speak': {'front': 1.0}, 'front': {'desk': 1.0}, 'desk': {'wa': 1.0}, 'wa': {'told': 1.0}, 'told': {'simpli': 0.5, 'receiv': 0.5}, 'simpli': {'honor': 0.5, 'poor': 0.5}, 'honor': {'request': 1.0}, 'request': {'upper': 0.4, 'better': 0.2, 'justifi': 0.2, 'room': 0.2}, 'upper': {'floor': 1.0}, 'better': {'view': 1.0}, 'view': {'look': 1.0}, 'look': {'brick': 1.0}, 'brick': {'wall': 1.0}, 'wall': {'get': 1.0}, 'get': {'sleep': 1.0}, 'sleep': {'also': 1.0}, 'also': {'told': 1.0}, 'receiv': {'complaint': 1.0}, 'complaint': {'befor': 1.0}, 'befor': {'guest': 1.0}, 'guest': {'th': 0.5, 'believ': 0.5}, 'th': {'floor': 1.0}, 'awar': {'nois': 1.0}, 'nois': {'problem': 1.0}, 'problem': {'whi': 1.0}, 'whi': {'place': 1.0}, 'us': {'thi': 1.0}, 'thi': {'floor': 0.3333, 'decid': 0.3333, 'simpli': 0.3333}, 'hotel': {'total': 1.0}, 'total': {'book': 1.0}, 'doe': {'constitut': 1.0}, 'constitut': {'place': 1.0}, 'someon': {'top': 1.0}, 'justifi': {'thi': 1.0}, 'decid': {'stay': 1.0}, 'stay': {'request': 1.0}, 'lower': {'floor': 1.0}, 'away': {'elev': 1.0}, 'spoke': {'length': 1.0}, 'length': {'book': 1.0}, 'prefer': {'thi': 1.0}, 'poor': {'treatment': 1.0}, 'treatment': {'guest': 1.0}, 'believ': {'would': 1.0}, 'would': {'complain': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "#parse unigrams from the string format 'P(word) = probability'\n",
    "def parse_unigrams(unigrams_str):\n",
    "    unigram_probs = {}\n",
    "    for entry in unigrams_str:\n",
    "        #extract word and probability\n",
    "        word = entry.split('(')[1].split(')')[0]  #extract word inside 'P(...)'\n",
    "        prob = float(entry.split('=')[1].strip())  #extract the probability\n",
    "        unigram_probs[word] = prob\n",
    "    return unigram_probs\n",
    "\n",
    "#parse bigrams from the string format 'P(next_word|current_word) = probability'\n",
    "def parse_bigrams(bigrams_str):\n",
    "    bigram_probs = {}\n",
    "    for entry in bigrams_str:\n",
    "        #extract current_word and next_word\n",
    "        next_word, current_word = entry.split('|')\n",
    "        current_word = current_word.split(')')[0].strip()  #remove extra characters\n",
    "        next_word = next_word.split('(')[1].strip()  #extract word inside 'P(...)'\n",
    "        prob = float(entry.split('=')[1].strip())  #extract the probability\n",
    "        \n",
    "        #store in dictionary as bigram_probs[current_word][next_word] = prob\n",
    "        if current_word not in bigram_probs:\n",
    "            bigram_probs[current_word] = {}\n",
    "        bigram_probs[current_word][next_word] = prob\n",
    "    return bigram_probs\n",
    "\n",
    "unigrams_str = df.unigrams[0]\n",
    "bigrams_str = df.bigrams[0]\n",
    "\n",
    "#example usage\n",
    "unigram_probs = parse_unigrams(unigrams_str)\n",
    "bigram_probs = parse_bigrams(bigrams_str)\n",
    "\n",
    "print(\"Unigram probabilities:\", unigram_probs)\n",
    "print(\"Bigram probabilities:\", bigram_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4273\n",
      "4256\n"
     ]
    }
   ],
   "source": [
    "#converting them to a single dictionary\n",
    "unigram_probs = df['unigrams'].apply(parse_unigrams)\n",
    "bigram_probs = df['bigrams'].apply(parse_bigrams)\n",
    "unigrams_dict = {}\n",
    "bigrams_dict = {}\n",
    "for d in unigram_probs:\n",
    "    unigrams_dict.update(d)\n",
    "\n",
    "for x in bigram_probs:\n",
    "    for key, subdict in x.items():\n",
    "        if key not in bigrams_dict:\n",
    "            bigrams_dict[key] = subdict\n",
    "        else: bigrams_dict[key].update(subdict)\n",
    "    \n",
    "print(len(unigrams_dict))\n",
    "print(len(bigrams_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate perplexity for both unigrams and bigrams\n",
    "def calculate_perplexity(test_corpus, bigram_probs=bigrams_dict, unigram_probs=unigrams_dict, model=\"bigram\"): #change model accordingly\n",
    "    log_prob_sum = 0\n",
    "    tokens = test_corpus.split()\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "        \n",
    "    if model == \"unigram\":       \n",
    "        for word in tokens:\n",
    "            prob = unigram_probs.get(word, unigram_probs.get(\"<unk>\", 1e-10))  # Use unigram probs or <unk>\n",
    "            log_prob_sum += math.log(prob)\n",
    "    \n",
    "    elif model == \"bigram\":    \n",
    "        for i in range(1, len(tokens)):\n",
    "            w1, w2 = tokens[i - 1], tokens[i]\n",
    "            \n",
    "            #check for bigram probability first\n",
    "            if w1 in bigram_probs and w2 in bigram_probs[w1]:\n",
    "                prob = bigram_probs[w1][w2]\n",
    "            else:\n",
    "                #fallback to unigram probability or <unk>\n",
    "                prob = unigram_probs.get(w2, unigram_probs.get(\"<unk>\", 1e-10))\n",
    "            log_prob_sum += math.log(prob)\n",
    "    \n",
    "    perplexity = math.exp(-log_prob_sum / total_words)\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "      <th>filtered</th>\n",
       "      <th>unigram perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stayed there three nights from 4/17/09 through...</td>\n",
       "      <td>stay three night checheck wait minut becaus sp...</td>\n",
       "      <td>stay three night &lt;unk&gt; wait minut &lt;unk&gt; specia...</td>\n",
       "      <td>207.679543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I stay at this hotel 2 times a year on busines...</td>\n",
       "      <td>stay thi hotel time year busi love staff great...</td>\n",
       "      <td>stay thi hotel time year busi love staff great...</td>\n",
       "      <td>58.896893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>On our visit to Chicago , we chose the Hyatt d...</td>\n",
       "      <td>visit chicago chose hyatt due locat downtown w...</td>\n",
       "      <td>visit chicago chose hyatt due locat downtown w...</td>\n",
       "      <td>287.889790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>October 3rd , 2007 My wife and I stayed at The...</td>\n",
       "      <td>octob rd wife stay sofitel toward end septemb ...</td>\n",
       "      <td>octob rd wife stay sofitel toward end septemb ...</td>\n",
       "      <td>166.249370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Striking architecture is only the beginning of...</td>\n",
       "      <td>strike architectur onli begin onli describ one...</td>\n",
       "      <td>strike architectur onli begin onli &lt;unk&gt; one b...</td>\n",
       "      <td>504.298237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  \\\n",
       "69  Stayed there three nights from 4/17/09 through...   \n",
       "30  I stay at this hotel 2 times a year on busines...   \n",
       "57  On our visit to Chicago , we chose the Hyatt d...   \n",
       "36  October 3rd , 2007 My wife and I stayed at The...   \n",
       "16  Striking architecture is only the beginning of...   \n",
       "\n",
       "                                                clean  \\\n",
       "69  stay three night checheck wait minut becaus sp...   \n",
       "30  stay thi hotel time year busi love staff great...   \n",
       "57  visit chicago chose hyatt due locat downtown w...   \n",
       "36  octob rd wife stay sofitel toward end septemb ...   \n",
       "16  strike architectur onli begin onli describ one...   \n",
       "\n",
       "                                             filtered  unigram perplexity  \n",
       "69  stay three night <unk> wait minut <unk> specia...          207.679543  \n",
       "30  stay thi hotel time year busi love staff great...           58.896893  \n",
       "57  visit chicago chose hyatt due locat downtown w...          287.889790  \n",
       "36  octob rd wife stay sofitel toward end septemb ...          166.249370  \n",
       "16  strike architectur onli begin onli <unk> one b...          504.298237  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['unigram perplexity'] = df_test['filtered'].apply(lambda x: calculate_perplexity(x, model='unigram'))\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "      <th>filtered</th>\n",
       "      <th>unigram perplexity</th>\n",
       "      <th>bigram perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>For a supposed 4-star hotel , I was not very i...</td>\n",
       "      <td>suppos star hotel wa veri impress akk lobbi wa...</td>\n",
       "      <td>&lt;unk&gt; star hotel wa veri impress &lt;unk&gt; lobbi w...</td>\n",
       "      <td>340.411330</td>\n",
       "      <td>57.211919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I arrived at the Sofitel for a joint leisure a...</td>\n",
       "      <td>arriv sofitel joint leisur busi fantast hotel ...</td>\n",
       "      <td>arriv sofitel &lt;unk&gt; leisur busi fantast hotel ...</td>\n",
       "      <td>134.125408</td>\n",
       "      <td>24.706696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>We have been for the first time in Chicago and...</td>\n",
       "      <td>first time chicago stay swissotel five night w...</td>\n",
       "      <td>first time chicago stay swissotel five night w...</td>\n",
       "      <td>1204.459270</td>\n",
       "      <td>259.849963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I stayed at the Allegro in July for 4 nights f...</td>\n",
       "      <td>stay allegro juli night busi trip room wa spot...</td>\n",
       "      <td>stay allegro juli night busi trip room wa spot...</td>\n",
       "      <td>134.049741</td>\n",
       "      <td>20.926259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Had a week long stay at the Hilton on south Mi...</td>\n",
       "      <td>week long stay hilton south michigan attend me...</td>\n",
       "      <td>week long stay hilton south michigan attend me...</td>\n",
       "      <td>322.358351</td>\n",
       "      <td>80.269685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>This was a great place to be ! Great views of ...</td>\n",
       "      <td>thi wa great place great view river lake walk ...</td>\n",
       "      <td>thi wa great place great view river lake walk ...</td>\n",
       "      <td>69.153358</td>\n",
       "      <td>10.170774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  \\\n",
       "18  For a supposed 4-star hotel , I was not very i...   \n",
       "33  I arrived at the Sofitel for a joint leisure a...   \n",
       "17  We have been for the first time in Chicago and...   \n",
       "28  I stayed at the Allegro in July for 4 nights f...   \n",
       "66  Had a week long stay at the Hilton on south Mi...   \n",
       "39  This was a great place to be ! Great views of ...   \n",
       "\n",
       "                                                clean  \\\n",
       "18  suppos star hotel wa veri impress akk lobbi wa...   \n",
       "33  arriv sofitel joint leisur busi fantast hotel ...   \n",
       "17  first time chicago stay swissotel five night w...   \n",
       "28  stay allegro juli night busi trip room wa spot...   \n",
       "66  week long stay hilton south michigan attend me...   \n",
       "39  thi wa great place great view river lake walk ...   \n",
       "\n",
       "                                             filtered  unigram perplexity  \\\n",
       "18  <unk> star hotel wa veri impress <unk> lobbi w...          340.411330   \n",
       "33  arriv sofitel <unk> leisur busi fantast hotel ...          134.125408   \n",
       "17  first time chicago stay swissotel five night w...         1204.459270   \n",
       "28  stay allegro juli night busi trip room wa spot...          134.049741   \n",
       "66  week long stay hilton south michigan attend me...          322.358351   \n",
       "39  thi wa great place great view river lake walk ...           69.153358   \n",
       "\n",
       "    bigram perplexity  \n",
       "18          57.211919  \n",
       "33          24.706696  \n",
       "17         259.849963  \n",
       "28          20.926259  \n",
       "66          80.269685  \n",
       "39          10.170774  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['bigram perplexity'] = df_test['filtered'].apply(lambda x: calculate_perplexity(x, model='bigram'))\n",
    "df_test.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict the next word using the unigram model\n",
    "def predict_next_word_unigram(unigram_probs):\n",
    "    #get the word with the highest unigram probability\n",
    "    next_word = max(unigram_probs, key=unigram_probs.get)\n",
    "    return next_word\n",
    "\n",
    "#function to predict the next word using the bigram model\n",
    "def predict_next_word_bigram(last_word, bigram_probs, unigram_probs):\n",
    "    #check if the last word exists in the bigram probabilities\n",
    "    if last_word in bigram_probs:\n",
    "        #get the next word with the highest bigram probability given the last word\n",
    "        next_word = max(bigram_probs[last_word], key=bigram_probs[last_word].get)\n",
    "    else:\n",
    "        #fallback to unigram model if no bigram is available for the last word\n",
    "        next_word = max(unigram_probs, key=unigram_probs.get)\n",
    "    return next_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram model prediction: enjoy\n",
      "Bigram model prediction: view\n"
     ]
    }
   ],
   "source": [
    "test_snippet = \"This was a great \"\n",
    "# Predict the next word using the unigram model\n",
    "next_word_unigram = predict_next_word_unigram(unigrams_dict)\n",
    "\n",
    "# Predict the next word using the bigram model\n",
    "last_word = test_snippet.split()[-1]\n",
    "next_word_bigram = predict_next_word_bigram(last_word, bigrams_dict, unigrams_dict)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Unigram model prediction: {next_word_unigram}\")\n",
    "print(f\"Bigram model prediction: {next_word_bigram}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
