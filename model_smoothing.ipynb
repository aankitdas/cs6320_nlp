{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pECPQaOABnaZ",
    "outputId": "7c635a7c-4aa6-45b4-e130-7ffa8b6c9a87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kedar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gCeOQGjd3RXB"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNt9yRiWBnad",
    "outputId": "68d1dc9b-f363-494c-9af8-a6d0de64cf8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kedar')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MJeCzxKGBnae"
   },
   "outputs": [],
   "source": [
    "with open(\"train.txt\", 'r') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "\n",
    "len(lines)\n",
    "\n",
    "test_sentence = lines[0]\n",
    "test_sentence = \"I booked 2 rooms four months in advance at the Talbott * . We were placed on the 1st floor next to the elevators , which are used all night long .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6KAYRqUzBnae",
    "outputId": "31959003-bd33-4628-b175-22acc785d885"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Swissotel continues to be a *yawn* As previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>My husband &amp; I stayed at the Fitzpatrick in ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>I stayed at the Hilton Chicago last week and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Just back from 5 night stay at Omni and would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>We booked our hotel stay thru Yahoo and reques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "507  Swissotel continues to be a *yawn* As previous...\n",
       "508  My husband & I stayed at the Fitzpatrick in ea...\n",
       "509  I stayed at the Hilton Chicago last week and w...\n",
       "510  Just back from 5 night stay at Omni and would ...\n",
       "511  We booked our hotel stay thru Yahoo and reques..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lines, columns=['reviews'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "yo2b3OzPBnae",
    "outputId": "d5f69d45-e154-4b17-f75a-7077555964eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2chMuKTVBnaf"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDQvJS_gBnaf",
    "outputId": "a49ad095-1edc-4818-953e-c9a2d7debe9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kedar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKVGpUeaBnaf",
    "outputId": "7845c68c-bda7-47b2-9880-0452a70b1046"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/kedar/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "vUCL_UHCBnag",
    "outputId": "258288d3-7031-4d62-e1b6-7da644761820"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I booked  rooms four months in advance at the Talbott   We were placed on the st floor next to the elevators  which are used all night long '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuations and digit\n",
    "filtered_sent = test_sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "filtered_sent = ''.join([char for char in filtered_sent if not char.isdigit()])\n",
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5S4mCkHtBnag",
    "outputId": "180ca505-584b-4861-a234-6e2c1a5377f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'booked', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the', 'Talbott', 'We', 'were', 'placed', 'on', 'the', 'st', 'floor', 'next', 'to', 'the', 'elevators', 'which', 'are', 'used', 'all', 'night', 'long']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(filtered_sent)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QS96K9-jBnag",
    "outputId": "d45f329b-8ee7-42b8-f3e3-aa5de7e601b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booked rooms four months advance Talbott placed st floor next elevators used night long\n"
     ]
    }
   ],
   "source": [
    "#removing stop words\n",
    "filtered_tokens = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "filtered_sent = ' '.join(filtered_tokens)\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Vnv9er-Bnah",
    "outputId": "2fc5da4b-b384-4e4e-d47d-fb8654453d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'room', 'four', 'month', 'advanc', 'talbott', 'place', 'st', 'floor', 'next', 'elev', 'use', 'night', 'long']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stem_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxC8zh8bBnah",
    "outputId": "cc9b2898-c4bd-4505-ec00-9abfcfb61ae3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kedar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['booked', 'room', 'four', 'month', 'advance', 'Talbott', 'placed', 'st', 'floor', 'next', 'elevator', 'used', 'night', 'long']\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lem_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(lem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oY2IASRD1MFX"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YZzxSvoTBnah"
   },
   "outputs": [],
   "source": [
    "#make a function to remove stop words and convert to lower case\n",
    "def preprocessing(sentence):\n",
    "    #print(type(sentence))\n",
    "    filtered_sent = sentence.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "    filtered_sent = ''.join([char for char in filtered_sent if not char.isdigit()]) #remove digits\n",
    "    word_tokens = word_tokenize(filtered_sent) #tokenize\n",
    "    filtered_tokens = [w for w in word_tokens if not w.lower() in stop_words] #removing stopwords\n",
    "    stem_tokens = [stemmer.stem(word) for word in filtered_tokens] #stemming\n",
    "    \n",
    "    filtered_sent = ' '.join(stem_tokens) #joining the tokens\n",
    "    return filtered_sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RlVgZW0J_jwg"
   },
   "outputs": [],
   "source": [
    "#creating a vocab from training data\n",
    "def handle_unk(data, threshold=1):\n",
    "    word_counts = Counter()\n",
    "    for sentences in data:\n",
    "        sentences = preprocessing(sentences)\n",
    "        sentences = sentences.lower().split()\n",
    "        word_counts.update(sentences)\n",
    "\n",
    "    vocab = {word for word, count in word_counts.items() if count > threshold}\n",
    "    return word_counts, vocab\n",
    "\n",
    "word_counts, vocab = handle_unk(lines,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "A2zCCY4A_spy"
   },
   "outputs": [],
   "source": [
    "#replacing unknown words with a token <unk>\n",
    "def replace_unk(sentences, vocab=vocab):\n",
    "\n",
    "    sentences = preprocessing(sentences)\n",
    "    sentences = sentences.lower().split()\n",
    "\n",
    "    x = [word if word in vocab else \"unkown_word\" for word in sentences]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "# replace unk in training set too\n",
    "lines = [replace_unk(sentence) for sentence in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foSXh_MdBnah",
    "outputId": "79a75b22-536c-4a23-fc51-952ecf5c67f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing: I booked 2 rooms four months in advance at the Talbott * . We were placed on the 1st floor next to the elevators , which are used all night long .\n",
      "After preprocessing: book room four month advanc talbott place st floor next elev use night long\n"
     ]
    }
   ],
   "source": [
    "test_sentence_clean = preprocessing(test_sentence)\n",
    "print(\"Before preprocessing:\", test_sentence)\n",
    "print(\"After preprocessing:\", test_sentence_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "_YAgDOzFBnah",
    "outputId": "f698bca2-2ac3-43bf-821f-fd6b740a0cf8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book two room four month advanc talbott place top floor next elev use night long speak front desk told simpli honor request upper floor request better view look brick wall get sleep also told receiv complaint guest th floor awar nois problem place us floor hotel total book request upper floor constitut place someon top floor use request justifi decid stay request room lower floor away elev spoke length book two room prefer simpli poor treatment guest believ would complain'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['reviews'].apply(lambda x: preprocessing(x))\n",
    "# add a new method to apply replace_unk to all the values in df['clean']\n",
    "df['clean'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZuO45vHBnah"
   },
   "source": [
    "Unigram counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ge9_xRDSKFYl"
   },
   "outputs": [],
   "source": [
    "# Dictionary to store unigrams\n",
    "unigrams = defaultdict(int)\n",
    "\n",
    "# Function to calculate unigrams for a sentence using nltk tokenizer\n",
    "def calculate_unigrams(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)  # Tokenize the sentence using nltk\n",
    "    unigram_counts = Counter(tokens)  # Count the frequency of each token\n",
    "    for token, count in unigram_counts.items():\n",
    "        unigrams[token] += count  # Add the count to the unigrams dictionary\n",
    "\n",
    "# Apply the function to each sentence in the 'clean' column\n",
    "df['unigram_counts'] =  df['clean'].apply(lambda x: calculate_unigrams(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4268\n"
     ]
    }
   ],
   "source": [
    "print(len(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tv3z5bZlBnai",
    "outputId": "8bc47f34-df6c-423a-9e9f-9c6ed0e3beb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back night stay omni would thoroughli recommend staff bent backward assist anyth matter minut great locat magnific mile lot adult unkown_word daughter find fault would extra charg tax etc room servic bar restaur cheap day would definit recommend especi famili\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "test_sentence = lines[510]\n",
    "#test_sentence = \"the students like the assignment\"\n",
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IBjTCF8Bnai",
    "outputId": "8b528d34-62a8-4240-c161-a5023204993f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back', 'night', 'stay', 'omni', 'would', 'thoroughli', 'recommend', 'staff', 'bent', 'backward', 'assist', 'anyth', 'matter', 'minut', 'great', 'locat', 'magnific', 'mile', 'lot', 'adult', 'unkown_word', 'daughter', 'find', 'fault', 'would', 'extra', 'charg', 'tax', 'etc', 'room', 'servic', 'bar', 'restaur', 'cheap', 'day', 'would', 'definit', 'recommend', 'especi', 'famili']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_test_sent = preprocessing(test_sentence)\n",
    "test_tokens = nltk.word_tokenize(test_sentence)\n",
    "print(test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayZdYieCBnaj"
   },
   "source": [
    "Bigram Counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "N3446cTFUaem"
   },
   "outputs": [],
   "source": [
    "bigram_probabs = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = defaultdict(Counter)\n",
    "\n",
    "def calc_bigrams(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Update bigram counts\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1, w2 = tokens[i], tokens[i + 1]\n",
    "        bigrams[w1][w2] += 1  # Increment the count for the bigram (w1, w2)\n",
    "\n",
    "\n",
    "bigrams_col = df['clean'].apply(lambda x: pd.Series(calc_bigrams(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "67iGDW147b8_"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(unigrams)\n",
    "\n",
    "def calc_laplace_ngrams():\n",
    "    k =1  # Smaller constant for smoothing\n",
    "    for w1 in bigrams:\n",
    "        total_w1 = unigrams[w1]  # Count of the first word in the bigram\n",
    "        for w2 in bigrams[w1]:\n",
    "            # Correct Laplace smoothing formula with smaller constant\n",
    "            #bigram_probabs[w1][w2] = (bigrams[w1][w2] + k) / (total_w1 + k * vocab_size)  \n",
    "            bigram_probabs[w1][w2] = (bigrams[w1][w2] +k) / (total_w1 +k*vocab_size )  \n",
    "\n",
    "        # Calculate probabilities for unobserved bigrams\n",
    "        for w2 in unigrams:  # Iterate over the vocabulary\n",
    "            if w2 not in bigrams[w1]:  # If the bigram (w1, w2) is not observed\n",
    "                bigram_probabs[w1][w2] = k / (total_w1 + k*vocab_size)  # Laplace smoothing for unobserved bigrams\n",
    "\n",
    "    # Create a list of bigrams with probabilities\n",
    "    list_bigrams = [f\"P({w2}|{w1}) = {bigram_probabs[w1][w2]:.4f}\" for w1 in bigram_probabs for w2 in bigram_probabs[w1]]\n",
    "    return list_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-bmzkqeBnak",
    "outputId": "eb24c85e-d4cd-4bd1-ff6b-2cf354e9eea4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"val.txt\", 'r') as file:\n",
    "    test_lines = [line.rstrip() for line in file]\n",
    "\n",
    "len(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-5AeRUJHBnak",
    "outputId": "c00f9c6d-85d0-481d-cd02-2f71cce619b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>My husband and I were very excited to be stayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Had a week long stay at the Hilton on south Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>If you love Brick Walls and Alleyways , then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Booked a room w/ a queen bed for 2 nights for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stayed there three nights from 4/17/09 through...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews\n",
       "65  My husband and I were very excited to be stayi...\n",
       "66  Had a week long stay at the Hilton on south Mi...\n",
       "67  If you love Brick Walls and Alleyways , then t...\n",
       "68  Booked a room w/ a queen bed for 2 nights for ...\n",
       "69  Stayed there three nights from 4/17/09 through..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test_lines, columns=['reviews'])\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "6VhnZ5U4Bnaq",
    "outputId": "cea6279b-3aff-46a7-8fc9-21170c80ffbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>My husband and I were very excited to be stayi...</td>\n",
       "      <td>husband excit stay conrad unfortun would never...</td>\n",
       "      <td>husband excit stay conrad unfortun would never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Had a week long stay at the Hilton on south Mi...</td>\n",
       "      <td>week long stay hilton south michigan attend me...</td>\n",
       "      <td>week long stay hilton south michigan attend me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>If you love Brick Walls and Alleyways , then t...</td>\n",
       "      <td>love brick wall alleyway view ask room face ri...</td>\n",
       "      <td>love brick wall unkown_word view ask room face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Booked a room w/ a queen bed for 2 nights for ...</td>\n",
       "      <td>book room w queen bed night wonder nye rather ...</td>\n",
       "      <td>book room w queen bed night wonder unkown_word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stayed there three nights from 4/17/09 through...</td>\n",
       "      <td>stay three night checheck wait minut special r...</td>\n",
       "      <td>stay three night unkown_word wait minut specia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews  \\\n",
       "65  My husband and I were very excited to be stayi...   \n",
       "66  Had a week long stay at the Hilton on south Mi...   \n",
       "67  If you love Brick Walls and Alleyways , then t...   \n",
       "68  Booked a room w/ a queen bed for 2 nights for ...   \n",
       "69  Stayed there three nights from 4/17/09 through...   \n",
       "\n",
       "                                                clean  \\\n",
       "65  husband excit stay conrad unfortun would never...   \n",
       "66  week long stay hilton south michigan attend me...   \n",
       "67  love brick wall alleyway view ask room face ri...   \n",
       "68  book room w queen bed night wonder nye rather ...   \n",
       "69  stay three night checheck wait minut special r...   \n",
       "\n",
       "                                             filtered  \n",
       "65  husband excit stay conrad unfortun would never...  \n",
       "66  week long stay hilton south michigan attend me...  \n",
       "67  love brick wall unkown_word view ask room face...  \n",
       "68  book room w queen bed night wonder unkown_word...  \n",
       "69  stay three night unkown_word wait minut specia...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['clean'] = df_test['reviews'].apply(lambda x: preprocessing(x))\n",
    "df_test['filtered'] = df_test['clean'].apply(lambda x: replace_unk(x,vocab))\n",
    "df_test.tail() #test data with all unknown words handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1db5i8lTBnaq",
    "outputId": "7a9afee0-8e6a-441d-8678-e859ca6152dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65    husband excit stay conrad unfortun would never...\n",
      "66    week long stay hilton south michigan attend me...\n",
      "67    love brick wall unkown_word view ask room face...\n",
      "68    book room w queen bed night wonder unkown_word...\n",
      "69    stay three night unkown_word wait minut specia...\n",
      "Name: filtered, dtype: object\n"
     ]
    }
   ],
   "source": [
    "unk_counts = df_test['filtered'].apply(lambda x: x.count('<unk>'))\n",
    "print(df_test['filtered'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "4hK7PGYXKxd_",
    "outputId": "4837a768-d5cf-431a-ea63-5d0eb42ae77c"
   },
   "outputs": [],
   "source": [
    "# Define a small constant probability for <unk> tokens\n",
    "import math\n",
    "UNK_PROB = 1e-3  # You can adjust this value as needed\n",
    "\n",
    "def calc_probabilities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Calculate unigram probabilities for the sentence\n",
    "    # Calculate bigram probabilities for the sentence\n",
    "    log_combined_prob = 0\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1 = tokens[i]\n",
    "        w2 = tokens[i + 1]\n",
    "        # Check bigram probability with fallback for unknown tokens\n",
    "        if w1 in bigram_probabs and w2 in bigram_probabs[w1]:\n",
    "            prob = bigram_probabs[w1][w2]\n",
    "        else:\n",
    "            prob = UNK_PROB  # Use small constant probability for unknown bigram\n",
    "\n",
    "        log_combined_prob += math.log(prob)\n",
    "\n",
    "    # Convert log probability back to probability\n",
    "\n",
    "    return log_combined_prob\n",
    "\n",
    "\n",
    "#result = calc_probabilities('book two room four month advanc talbott place top floor next elev use night long speak front desk told simpli honor request upper floor request better view look brick wall get sleep also told receiv complaint guest th floor awar nois problem place us floor hotel total book request upper floor constitut place someon top floor use request justifi decid stay request room lower floor away elev spoke length book two room prefer simpli poor treatment guest believ would complain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['log_prob_laplace'] = df_test['filtered'].apply(lambda x: pd.Series(calc_probabilities(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -283.217966\n",
       "1    -310.848988\n",
       "2    -366.111030\n",
       "3    -676.960017\n",
       "4    -504.266135\n",
       "         ...    \n",
       "65   -628.605730\n",
       "66   -462.819604\n",
       "67   -414.465317\n",
       "68   -511.173891\n",
       "69   -172.693882\n",
       "Name: log_prob_laplace, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['log_prob_laplace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(df_test, col):\n",
    "    # Sum of log probabilities (already computed in 'log_prob_laplace')\n",
    "    total_log_prob = df_test[col].sum()\n",
    "\n",
    "    # Total number of tokens in the dataset (assuming 'filtered' column has the sentences)\n",
    "    #total_tokens = df_test['filtered'].apply(lambda x: len(nltk.word_tokenize(x))).sum()\n",
    "    total_tokens = 9811\n",
    "    # Calculate perplexity\n",
    "    perplexity = 2**(-total_log_prob / total_tokens)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Call the function to calculate the perplexity for all sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_perplexity = calculate_perplexity(df_test, 'log_prob_laplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace perplexity:  7.922823656032202\n"
     ]
    }
   ],
   "source": [
    "print(\"Laplace perplexity: \", laplace_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_probs = defaultdict(lambda: defaultdict(float))\n",
    "def calc_kneser_ney_prob(token, d=0.75):\n",
    "    # Count of the bigram (w1, w2)\n",
    "    token = token.split(' ')\n",
    "    for i in range(len(token)-1):\n",
    "        w1=token[i]\n",
    "        w2=token[i+1]\n",
    "        bigram_count = bigrams[w1][w2]\n",
    "\n",
    "        # Count of the unigram w1\n",
    "        unigram_count = unigrams[w1]\n",
    "\n",
    "        # Continuation probability P(w2)\n",
    "        continuation_count = sum(1 for w in bigrams if w2 in bigrams[w])\n",
    "        total_bigrams = sum(len(bigrams[w1]) for w1 in bigrams)  # Total number of unique bigrams\n",
    "        continuation_prob = continuation_count / total_bigrams if total_bigrams > 0 else 0\n",
    "\n",
    "        # Calculate Kneser-Ney probability\n",
    "        if bigram_count > 0:\n",
    "        # Normal bigram probability with discount\n",
    "            kneser_ney_prob = max(bigram_count - d, 0) / unigram_count + (d * continuation_prob) / total_bigrams\n",
    "        else:\n",
    "        # Backoff to continuation probability\n",
    "            kneser_ney_prob = (d * continuation_prob) / total_bigrams\n",
    "\n",
    "\n",
    "        kn_probs[w1][w2] = kneser_ney_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df['kn'] = df['clean'].apply(lambda x:calc_kneser_ney_prob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small constant probability for <unk> tokens\n",
    "import math\n",
    "UNK_PROB = 1e-3  # You can adjust this value as needed\n",
    "\n",
    "def calc_kn_probabilities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Initialize the log combined probability\n",
    "    log_combined_prob = 0\n",
    "    \n",
    "    calc_kneser_ney_prob(sentence)  \n",
    "    # Calculate bigram probabilities for the sentence using Kneser-Ney\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1 = tokens[i]\n",
    "        w2 = tokens[i + 1]\n",
    "\n",
    "        # Call the Kneser-Ney function to get the probability for the bigram (w1, w2)\n",
    "        if w1 == 'unkown_word' or w2 == 'unkown_word':\n",
    "            prob = UNK_PROB  # Use a small constant probability for any unknown token bigram\n",
    "        else:\n",
    "            # For known tokens, calculate the Kneser-Ney probability for the bigram (w1, w2)\n",
    "            # Ensure the Kneser-Ney probabilities are calculated\n",
    "            prob = kn_probs[w1][w2]  # Retrieve the Kneser-Ney probability\n",
    "        if prob == 0:\n",
    "            print(tokens)\n",
    "            print(sentence)\n",
    "        log_combined_prob += math.log(prob)\n",
    "\n",
    "\n",
    "\n",
    "    # Return the combined log probability\n",
    "    return log_combined_prob\n",
    "\n",
    "\n",
    "#result = calc_probabilities('book two room four month advanc talbott place top floor next elev use night long speak front desk told simpli honor request upper floor request better view look brick wall get sleep also told receiv complaint guest th floor awar nois problem place us floor hotel total book request upper floor constitut place someon top floor use request justifi decid stay request room lower floor away elev spoke length book two room prefer simpli poor treatment guest believ would complain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['log_prob_kn'] = df_test['filtered'].apply(lambda x: pd.Series(calc_kn_probabilities(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -398.652625\n",
       "1     -488.906002\n",
       "2     -621.026972\n",
       "3     -903.615911\n",
       "4     -693.060096\n",
       "         ...     \n",
       "65   -1011.585753\n",
       "66    -662.674746\n",
       "67    -670.617220\n",
       "68    -855.337985\n",
       "69    -255.918032\n",
       "Name: log_prob_kn, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['log_prob_kn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_perplexity = calculate_perplexity(df_test, 'log_prob_kn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kneser ney perplexity:  27.196438409134966\n"
     ]
    }
   ],
   "source": [
    "print(\"Kneser ney perplexity: \", kn_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add k smoothing\n",
    "vocab_size = len(unigrams)\n",
    "bigram_probabs_addk=defaultdict(dict)\n",
    "def calc_addk_ngrams():\n",
    "    k =0.01  # Smaller constant for smoothing\n",
    "    for w1 in bigrams:\n",
    "        total_w1 = unigrams[w1]  # Count of the first word in the bigram\n",
    "        for w2 in bigrams[w1]:\n",
    "            # Correct addl smoothing formula with smaller constant\n",
    "            bigram_probabs_addk[w1][w2] = (bigrams[w1][w2] +k) / (total_w1 +k*vocab_size )  \n",
    "\n",
    "        # Calculate probabilities for unobserved bigrams\n",
    "        for w2 in unigrams:  # Iterate over the vocabulary\n",
    "            if w2 not in bigrams[w1]:  # If the bigram (w1, w2) is not observed\n",
    "                bigram_probabs_addk[w1][w2] = k / (total_w1 + k*vocab_size)  # Laplace smoothing for unobserved bigrams\n",
    "\n",
    "    # Create a list of bigrams with probabilities\n",
    "    list_bigrams = [f\"P({w2}|{w1}) = {bigram_probabs_addk[w1][w2]:.4f}\" for w1 in bigram_probabs_addk for w2 in bigram_probabs_addk[w1]]\n",
    "    return list_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P(two|book) = 0.0187',\n",
       " 'P(request|book) = 0.0063',\n",
       " 'P(ambassador|book) = 0.0063',\n",
       " 'P(us|book) = 0.0187',\n",
       " 'P(flight|book) = 0.0063',\n",
       " 'P(pick|book) = 0.0063',\n",
       " 'P(even|book) = 0.0063',\n",
       " 'P(via|book) = 0.0187',\n",
       " 'P(hotel|book) = 0.1307',\n",
       " 'P(upgrad|book) = 0.0063',\n",
       " 'P(pricelin|book) = 0.0250',\n",
       " 'P(reserv|book) = 0.0125',\n",
       " 'P(amalfi|book) = 0.0125',\n",
       " 'P(directli|book) = 0.0125',\n",
       " 'P(room|book) = 0.1121',\n",
       " 'P(block|book) = 0.0063',\n",
       " 'P(suit|book) = 0.0063',\n",
       " 'P(anoth|book) = 0.0063',\n",
       " 'P(allegro|book) = 0.0063',\n",
       " 'P(guess|book) = 0.0063',\n",
       " 'P(solid|book) = 0.0063',\n",
       " 'P(share|book) = 0.0063',\n",
       " 'P(dinner|book) = 0.0063',\n",
       " 'P(thought|book) = 0.0063',\n",
       " 'P(omni|book) = 0.0063',\n",
       " 'P(packag|book) = 0.0125',\n",
       " 'P(five|book) = 0.0063',\n",
       " 'P(one|book) = 0.0063',\n",
       " 'P(teen|book) = 0.0063',\n",
       " 'P(told|book) = 0.0063',\n",
       " 'P(conrad|book) = 0.0063',\n",
       " 'P(group|book) = 0.0063',\n",
       " 'P(sofitel|book) = 0.0063',\n",
       " 'P(stay|book) = 0.0187',\n",
       " 'P(cd|book) = 0.0063',\n",
       " 'P(dumpi|book) = 0.0063',\n",
       " 'P(internet|book) = 0.0063',\n",
       " 'P(travelzoo|book) = 0.0063',\n",
       " 'P(whole|book) = 0.0063',\n",
       " 'P(paid|book) = 0.0063',\n",
       " 'P(night|book) = 0.0063',\n",
       " 'P(take|book) = 0.0063',\n",
       " 'P(ticket|book) = 0.0063',\n",
       " 'P(rate|book) = 0.0063',\n",
       " 'P(roomnight|book) = 0.0063',\n",
       " 'P(still|book) = 0.0063',\n",
       " 'P(leav|book) = 0.0063',\n",
       " 'P(thru|book) = 0.0063',\n",
       " 'P(window|book) = 0.0063',\n",
       " 'P(ps|book) = 0.0063',\n",
       " 'P(anywher|book) = 0.0063',\n",
       " 'P(elsewher|book) = 0.0063',\n",
       " 'P(nonsmok|book) = 0.0063',\n",
       " 'P(base|book) = 0.0063',\n",
       " 'P(yet|book) = 0.0063',\n",
       " 'P(coupl|book) = 0.0063',\n",
       " 'P(refiger|book) = 0.0063',\n",
       " 'P(kingcorn|book) = 0.0063',\n",
       " 'P(phone|book) = 0.0063',\n",
       " 'P(nonrefun|book) = 0.0063',\n",
       " 'P(hotwir|book) = 0.0063',\n",
       " 'P(airhotel|book) = 0.0063',\n",
       " 'P(nonrefund|book) = 0.0063',\n",
       " 'P(famili|book) = 0.0063',\n",
       " 'P(said|book) = 0.0063',\n",
       " 'P(onlin|book) = 0.0063',\n",
       " 'P(book|book) = 0.0001',\n",
       " 'P(four|book) = 0.0001',\n",
       " 'P(month|book) = 0.0001',\n",
       " 'P(advanc|book) = 0.0001',\n",
       " 'P(talbott|book) = 0.0001',\n",
       " 'P(place|book) = 0.0001',\n",
       " 'P(top|book) = 0.0001',\n",
       " 'P(floor|book) = 0.0001',\n",
       " 'P(next|book) = 0.0001',\n",
       " 'P(elev|book) = 0.0001',\n",
       " 'P(use|book) = 0.0001',\n",
       " 'P(long|book) = 0.0001',\n",
       " 'P(speak|book) = 0.0001',\n",
       " 'P(front|book) = 0.0001',\n",
       " 'P(desk|book) = 0.0001',\n",
       " 'P(simpli|book) = 0.0001',\n",
       " 'P(honor|book) = 0.0001',\n",
       " 'P(upper|book) = 0.0001',\n",
       " 'P(better|book) = 0.0001',\n",
       " 'P(view|book) = 0.0001',\n",
       " 'P(look|book) = 0.0001',\n",
       " 'P(brick|book) = 0.0001',\n",
       " 'P(wall|book) = 0.0001',\n",
       " 'P(get|book) = 0.0001',\n",
       " 'P(sleep|book) = 0.0001',\n",
       " 'P(also|book) = 0.0001',\n",
       " 'P(receiv|book) = 0.0001',\n",
       " 'P(complaint|book) = 0.0001',\n",
       " 'P(guest|book) = 0.0001',\n",
       " 'P(th|book) = 0.0001',\n",
       " 'P(awar|book) = 0.0001',\n",
       " 'P(nois|book) = 0.0001',\n",
       " 'P(problem|book) = 0.0001',\n",
       " 'P(total|book) = 0.0001',\n",
       " 'P(constitut|book) = 0.0001',\n",
       " 'P(someon|book) = 0.0001',\n",
       " 'P(justifi|book) = 0.0001',\n",
       " 'P(decid|book) = 0.0001',\n",
       " 'P(lower|book) = 0.0001',\n",
       " 'P(away|book) = 0.0001',\n",
       " 'P(spoke|book) = 0.0001',\n",
       " 'P(length|book) = 0.0001',\n",
       " 'P(prefer|book) = 0.0001',\n",
       " 'P(poor|book) = 0.0001',\n",
       " 'P(treatment|book) = 0.0001',\n",
       " 'P(believ|book) = 0.0001',\n",
       " 'P(would|book) = 0.0001',\n",
       " 'P(complain|book) = 0.0001',\n",
       " 'P(love|book) = 0.0001',\n",
       " 'P(chic|book) = 0.0001',\n",
       " 'P(trendi|book) = 0.0001',\n",
       " 'P(bed|book) = 0.0001',\n",
       " 'P(comfort|book) = 0.0001',\n",
       " 'P(great|book) = 0.0001',\n",
       " 'P(slipper|book) = 0.0001',\n",
       " 'P(robe|book) = 0.0001',\n",
       " 'P(keihl|book) = 0.0001',\n",
       " 'P(bath|book) = 0.0001',\n",
       " 'P(product|book) = 0.0001',\n",
       " 'P(bathroom|book) = 0.0001',\n",
       " 'P(went|book) = 0.0001',\n",
       " 'P(birthday|book) = 0.0001',\n",
       " 'P(weekend|book) = 0.0001',\n",
       " 'P(card|book) = 0.0001',\n",
       " 'P(plate|book) = 0.0001',\n",
       " 'P(pastri|book) = 0.0001',\n",
       " 'P(wait|book) = 0.0001',\n",
       " 'P(got|book) = 0.0001',\n",
       " 'P(deal|book) = 0.0001',\n",
       " 'P(junior|book) = 0.0001',\n",
       " 'P(tri|book) = 0.0001',\n",
       " 'P(trip|book) = 0.0001',\n",
       " 'P(chicago|book) = 0.0001',\n",
       " 'P(gone|book) = 0.0001',\n",
       " 'P(realli|book) = 0.0001',\n",
       " 'P(recommend|book) = 0.0001',\n",
       " 'P(david|book) = 0.0001',\n",
       " 'P(burk|book) = 0.0001',\n",
       " 'P(steakhous|book) = 0.0001',\n",
       " 'P(servic|book) = 0.0001',\n",
       " 'P(horribl|book) = 0.0001',\n",
       " 'P(switch|book) = 0.0001',\n",
       " 'P(order|book) = 0.0001',\n",
       " 'P(tabl|book) = 0.0001',\n",
       " 'P(compens|book) = 0.0001',\n",
       " 'P(took|book) = 0.0001',\n",
       " 'P(side|book) = 0.0001',\n",
       " 'P(dish|book) = 0.0001',\n",
       " 'P(nice|book) = 0.0001',\n",
       " 'P(enough|book) = 0.0001',\n",
       " 'P(charg|book) = 0.0001',\n",
       " 'P(nt|book) = 0.0001',\n",
       " 'P(go|book) = 0.0001',\n",
       " 'P(lawri|book) = 0.0001',\n",
       " 'P(accross|book) = 0.0001',\n",
       " 'P(street|book) = 0.0001',\n",
       " 'P(jame|book) = 0.0001',\n",
       " 'P(btw|book) = 0.0001',\n",
       " 'P(star|book) = 0.0001',\n",
       " 'P(like|book) = 0.0001',\n",
       " 'P(websit|book) = 0.0001',\n",
       " 'P(list|book) = 0.0001',\n",
       " 'P(least|book) = 0.0001',\n",
       " 'P(hard|book) = 0.0001',\n",
       " 'P(rock|book) = 0.0001',\n",
       " 'P(becom|book) = 0.0001',\n",
       " 'P(favorit|book) = 0.0001',\n",
       " 'P(time|book) = 0.0001',\n",
       " 'P(never|book) = 0.0001',\n",
       " 'P(anyth|book) = 0.0001',\n",
       " 'P(wonder|book) = 0.0001',\n",
       " 'P(experi|book) = 0.0001',\n",
       " 'P(might|book) = 0.0001',\n",
       " 'P(super|book) = 0.0001',\n",
       " 'P(roll|book) = 0.0001',\n",
       " 'P(theme|book) = 0.0001',\n",
       " 'P(music|book) = 0.0001',\n",
       " 'P(paraphanelia|book) = 0.0001',\n",
       " 'P(lobbi|book) = 0.0001',\n",
       " 'P(larg|book) = 0.0001',\n",
       " 'P(photo|book) = 0.0001',\n",
       " 'P(mural|book) = 0.0001',\n",
       " 'P(differ|book) = 0.0001',\n",
       " 'P(musician|book) = 0.0001',\n",
       " 'P(band|book) = 0.0001',\n",
       " 'P(kiss|book) = 0.0001',\n",
       " 'P(aerosmith|book) = 0.0001',\n",
       " 'P(etc|book) = 0.0001',\n",
       " 'P(well|book) = 0.0001',\n",
       " 'P(appoint|book) = 0.0001',\n",
       " 'P(luxuri|book) = 0.0001',\n",
       " 'P(sheet|book) = 0.0001',\n",
       " 'P(pillow|book) = 0.0001',\n",
       " 'P(tv|book) = 0.0001',\n",
       " 'P(cool|book) = 0.0001',\n",
       " 'P(sound|book) = 0.0001',\n",
       " 'P(system|book) = 0.0001',\n",
       " 'P(ramp|book) = 0.0001',\n",
       " 'P(spaciou|book) = 0.0001',\n",
       " 'P(mini|book) = 0.0001',\n",
       " 'P(bar|book) = 0.0001',\n",
       " 'P(alway|book) = 0.0001',\n",
       " 'P(big|book) = 0.0001',\n",
       " 'P(michigan|book) = 0.0001',\n",
       " 'P(ave|book) = 0.0001',\n",
       " 'P(sit|book) = 0.0001',\n",
       " 'P(right|book) = 0.0001',\n",
       " 'P(canal|book) = 0.0001',\n",
       " 'P(furnish|book) = 0.0001',\n",
       " 'P(absolut|book) = 0.0001',\n",
       " 'P(fixtur|book) = 0.0001',\n",
       " 'P(sport|book) = 0.0001',\n",
       " 'P(design|book) = 0.0001',\n",
       " 'P(shower|book) = 0.0001',\n",
       " 'P(enjoy|book) = 0.0001',\n",
       " 'P(close|book) = 0.0001',\n",
       " 'P(waterproof|book) = 0.0001',\n",
       " 'P(drape|book) = 0.0001',\n",
       " 'P(staff|book) = 0.0001',\n",
       " 'P(doorman|book) = 0.0001',\n",
       " 'P(feel|book) = 0.0001',\n",
       " 'P(intim|book) = 0.0001',\n",
       " 'P(energi|book) = 0.0001',\n",
       " 'P(screen|book) = 0.0001',\n",
       " 'P(catch|book) = 0.0001',\n",
       " 'P(latest|book) = 0.0001',\n",
       " 'P(score|book) = 0.0001',\n",
       " 'P(cours|book) = 0.0001',\n",
       " 'P(pump|book) = 0.0001',\n",
       " 'P(plain|book) = 0.0001',\n",
       " 'P(fun|book) = 0.0001',\n",
       " 'P(memor|book) = 0.0001',\n",
       " 'P(want|book) = 0.0001',\n",
       " 'P(return|book) = 0.0001',\n",
       " 'P(back|book) = 0.0001',\n",
       " 'P(concern|book) = 0.0001',\n",
       " 'P(rather|book) = 0.0001',\n",
       " 'P(crazi|book) = 0.0001',\n",
       " 'P(park|book) = 0.0001',\n",
       " 'P(car|book) = 0.0001',\n",
       " 'P(overnight|book) = 0.0001',\n",
       " 'P(daili|book) = 0.0001',\n",
       " 'P(per|book) = 0.0001',\n",
       " 'P(sorri|book) = 0.0001',\n",
       " 'P(say|book) = 0.0001',\n",
       " 'P(loop|book) = 0.0001',\n",
       " 'P(frigid|book) = 0.0001',\n",
       " 'P(east|book) = 0.0001',\n",
       " 'P(aaa|book) = 0.0001',\n",
       " 'P(delight|book) = 0.0001',\n",
       " 'P(ye|book) = 0.0001',\n",
       " 'P(show|book) = 0.0001',\n",
       " 'P(sign|book) = 0.0001',\n",
       " 'P(wear|book) = 0.0001',\n",
       " 'P(warmth|book) = 0.0001',\n",
       " 'P(charm|book) = 0.0001',\n",
       " 'P(far|book) = 0.0001',\n",
       " 'P(make|book) = 0.0001',\n",
       " 'P(pleasant|book) = 0.0001',\n",
       " 'P(chang|book) = 0.0001',\n",
       " 'P(sleek|book) = 0.0001',\n",
       " 'P(modern|book) = 0.0001',\n",
       " 'P(mani|book) = 0.0001',\n",
       " 'P(chain|book) = 0.0001',\n",
       " 'P(boutiqu|book) = 0.0001',\n",
       " 'P(becam|book) = 0.0001',\n",
       " 'P(member|book) = 0.0001',\n",
       " 'P(program|book) = 0.0001',\n",
       " 'P(therefor|book) = 0.0001',\n",
       " 'P(elig|book) = 0.0001',\n",
       " 'P(automat|book) = 0.0001',\n",
       " 'P(upon|book) = 0.0001',\n",
       " 'P(check|book) = 0.0001',\n",
       " 'P(lot|book) = 0.0001',\n",
       " 'P(bedroom|book) = 0.0001',\n",
       " 'P(food|book) = 0.0001',\n",
       " 'P(classic|book) = 0.0001',\n",
       " 'P(oatmeal|book) = 0.0001',\n",
       " 'P(tast|book) = 0.0001',\n",
       " 'P(serv|book) = 0.0001',\n",
       " 'P(locat|book) = 0.0001',\n",
       " 'P(normal|book) = 0.0001',\n",
       " 'P(winter|book) = 0.0001',\n",
       " 'P(weather|book) = 0.0001',\n",
       " 'P(could|book) = 0.0001',\n",
       " 'P(easili|book) = 0.0001',\n",
       " 'P(walk|book) = 0.0001',\n",
       " 'P(avenu|book) = 0.0001',\n",
       " 'P(shop|book) = 0.0001',\n",
       " 'P(due|book) = 0.0001',\n",
       " 'P(minu|book) = 0.0001',\n",
       " 'P(degre|book) = 0.0001',\n",
       " 'P(windchil|book) = 0.0001',\n",
       " 'P(opt|book) = 0.0001',\n",
       " 'P(cab|book) = 0.0001',\n",
       " 'P(less|book) = 0.0001',\n",
       " 'P(fare|book) = 0.0001',\n",
       " 'P(glass|book) = 0.0001',\n",
       " 'P(wine|book) = 0.0001',\n",
       " 'P(around|book) = 0.0001',\n",
       " 'P(fireplac|book) = 0.0001',\n",
       " 'P(found|book) = 0.0001',\n",
       " 'P(welcom|book) = 0.0001',\n",
       " 'P(cozi|book) = 0.0001',\n",
       " 'P(overcrow|book) = 0.0001',\n",
       " 'P(definit|book) = 0.0001',\n",
       " 'P(worst|book) = 0.0001',\n",
       " 'P(receptionist|book) = 0.0001',\n",
       " 'P(snooti|book) = 0.0001',\n",
       " 'P(sarcast|book) = 0.0001',\n",
       " 'P(teenag|book) = 0.0001',\n",
       " 'P(post|book) = 0.0001',\n",
       " 'P(waiter|book) = 0.0001',\n",
       " 'P(waitress|book) = 0.0001',\n",
       " 'P(diner|book) = 0.0001',\n",
       " 'P(dirti|book) = 0.0001',\n",
       " 'P(stain|book) = 0.0001',\n",
       " 'P(carpet|book) = 0.0001',\n",
       " 'P(showerhead|book) = 0.0001',\n",
       " 'P(moldi|book) = 0.0001',\n",
       " 'P(rust|book) = 0.0001',\n",
       " 'P(door|book) = 0.0001',\n",
       " 'P(main|book) = 0.0001',\n",
       " 'P(dent|book) = 0.0001',\n",
       " 'P(scratch|book) = 0.0001',\n",
       " 'P(towel|book) = 0.0001',\n",
       " 'P(aroma|book) = 0.0001',\n",
       " 'P(narrow|book) = 0.0001',\n",
       " 'P(near|book) = 0.0001',\n",
       " 'P(construct|book) = 0.0001',\n",
       " 'P(zone|book) = 0.0001',\n",
       " 'P(plan|book) = 0.0001',\n",
       " 'P(wake|book) = 0.0001',\n",
       " 'P(choos|book) = 0.0001',\n",
       " 'P(day|book) = 0.0001',\n",
       " 'P(ask|book) = 0.0001',\n",
       " 'P(concierg|book) = 0.0001',\n",
       " 'P(decent|book) = 0.0001',\n",
       " 'P(guy|book) = 0.0001',\n",
       " 'P(move|book) = 0.0001',\n",
       " 'P(larger|book) = 0.0001',\n",
       " 'P(though|book) = 0.0001',\n",
       " 'P(tortur|book) = 0.0001',\n",
       " 'P(hear|book) = 0.0001',\n",
       " 'P(stop|book) = 0.0001',\n",
       " 'P(late|book) = 0.0001',\n",
       " 'P(checkout|book) = 0.0001',\n",
       " 'P(pm|book) = 0.0001',\n",
       " 'P(refus|book) = 0.0001',\n",
       " 'P(state|book) = 0.0001',\n",
       " 'P(half|book) = 0.0001',\n",
       " 'P(noon|book) = 0.0001',\n",
       " 'P(manag|book) = 0.0001',\n",
       " 'P(gave|book) = 0.0001',\n",
       " 'P(till|book) = 0.0001',\n",
       " 'P(pleas|book) = 0.0001',\n",
       " 'P(think|book) = 0.0001',\n",
       " 'P(holiday|book) = 0.0001',\n",
       " 'P(inn|book) = 0.0001',\n",
       " 'P(andrew|book) = 0.0001',\n",
       " 'P(f|book) = 0.0001',\n",
       " 'P(gulli|book) = 0.0001',\n",
       " 'P(wife|book) = 0.0001',\n",
       " 'P(came|book) = 0.0001',\n",
       " 'P(spend|book) = 0.0001',\n",
       " 'P(downtown|book) = 0.0001',\n",
       " 'P(everyth|book) = 0.0001',\n",
       " 'P(size|book) = 0.0001',\n",
       " 'P(lost|book) = 0.0001',\n",
       " 'P(convent|book) = 0.0001',\n",
       " 'P(world|book) = 0.0001',\n",
       " 'P(past|book) = 0.0001',\n",
       " 'P(bit|book) = 0.0001',\n",
       " 'P(lake|book) = 0.0001',\n",
       " 'P(end|book) = 0.0001',\n",
       " 'P(profession|book) = 0.0001',\n",
       " 'P(friendli|book) = 0.0001',\n",
       " 'P(free|book) = 0.0001',\n",
       " 'P(n|book) = 0.0001',\n",
       " 'P(review|book) = 0.0001',\n",
       " 'P(arriv|book) = 0.0001',\n",
       " 'P(good|book) = 0.0001',\n",
       " 'P(find|book) = 0.0001',\n",
       " 'P(pictur|book) = 0.0001',\n",
       " 'P(mislead|book) = 0.0001',\n",
       " 'P(loung|book) = 0.0001',\n",
       " 'P(odd|book) = 0.0001',\n",
       " 'P(dark|book) = 0.0001',\n",
       " 'P(first|book) = 0.0001',\n",
       " 'P(notic|book) = 0.0001',\n",
       " 'P(blanket|book) = 0.0001',\n",
       " 'P(nasti|book) = 0.0001',\n",
       " 'P(resembl|book) = 0.0001',\n",
       " 'P(someth|book) = 0.0001',\n",
       " 'P(woke|book) = 0.0001',\n",
       " 'P(bug|book) = 0.0001',\n",
       " 'P(attack|book) = 0.0001',\n",
       " 'P(husband|book) = 0.0001',\n",
       " 'P(bitten|book) = 0.0001',\n",
       " 'P(way|book) = 0.0001',\n",
       " 'P(leg|book) = 0.0001',\n",
       " 'P(cover|book) = 0.0001',\n",
       " 'P(bite|book) = 0.0001',\n",
       " 'P(ointment|book) = 0.0001',\n",
       " 'P(benadryl|book) = 0.0001',\n",
       " 'P(week|book) = 0.0001',\n",
       " 'P(immedi|book) = 0.0001',\n",
       " 'P(home|book) = 0.0001',\n",
       " 'P(scald|book) = 0.0001',\n",
       " 'P(cloth|book) = 0.0001',\n",
       " 'P(mold|book) = 0.0001',\n",
       " 'P(tub|book) = 0.0001',\n",
       " 'P(insid|book) = 0.0001',\n",
       " 'P(curl|book) = 0.0001',\n",
       " 'P(roof|book) = 0.0001',\n",
       " 'P(disappoint|book) = 0.0001',\n",
       " 'P(thing|book) = 0.0001',\n",
       " 'P(breakfast|book) = 0.0001',\n",
       " 'P(everi|book) = 0.0001',\n",
       " 'P(recent|book) = 0.0001',\n",
       " 'P(twonight|book) = 0.0001',\n",
       " 'P(visit|book) = 0.0001',\n",
       " 'P(mission|book) = 0.0001',\n",
       " 'P(accomplish|book) = 0.0001',\n",
       " 'P(quiet|book) = 0.0001',\n",
       " 'P(area|book) = 0.0001',\n",
       " 'P(age|book) = 0.0001',\n",
       " 'P(detract|book) = 0.0001',\n",
       " 'P(eleg|book) = 0.0001',\n",
       " 'P(style|book) = 0.0001',\n",
       " 'P(add|book) = 0.0001',\n",
       " 'P(homelik|book) = 0.0001',\n",
       " 'P(help|book) = 0.0001',\n",
       " 'P(futur|book) = 0.0001',\n",
       " 'P(sure|book) = 0.0001',\n",
       " 'P(import|book) = 0.0001',\n",
       " 'P(document|book) = 0.0001',\n",
       " 'P(call|book) = 0.0001',\n",
       " 'P(depart|book) = 0.0001',\n",
       " 'P(seven|book) = 0.0001',\n",
       " 'P(eventu|book) = 0.0001',\n",
       " 'P(put|book) = 0.0001',\n",
       " 'P(hold|book) = 0.0001',\n",
       " 'P(disconnect|book) = 0.0001',\n",
       " 'P(final|book) = 0.0001',\n",
       " 'P(deceivingli|book) = 0.0001',\n",
       " 'P(oper|book) = 0.0001',\n",
       " 'P(promis|book) = 0.0001',\n",
       " 'P(minut|book) = 0.0001',\n",
       " 'P(happen|book) = 0.0001',\n",
       " 'P(avoid|book) = 0.0001',\n",
       " 'P(rip|book) = 0.0001',\n",
       " 'P(keep|book) = 0.0001',\n",
       " 'P(later|book) = 0.0001',\n",
       " 'P(trust|book) = 0.0001',\n",
       " 'P(word|book) = 0.0001',\n",
       " 'P(warn|book) = 0.0001',\n",
       " 'P(poison|book) = 0.0001',\n",
       " 'P(alert|book) = 0.0001',\n",
       " 'P(handl|book) = 0.0001',\n",
       " 'P(daughter|book) = 0.0001',\n",
       " 'P(crack|book) = 0.0001',\n",
       " 'P(head|book) = 0.0001',\n",
       " 'P(open|book) = 0.0001',\n",
       " 'P(absolutli|book) = 0.0001',\n",
       " 'P(terribl|book) = 0.0001',\n",
       " 'P(made|book) = 0.0001',\n",
       " 'P(dizzi|book) = 0.0001',\n",
       " 'P(hade|book) = 0.0001',\n",
       " 'P(pasta|book) = 0.0001',\n",
       " 'P(bowl|book) = 0.0001',\n",
       " 'P(noodl|book) = 0.0001',\n",
       " 'P(sauc|book) = 0.0001',\n",
       " 'P(pay|book) = 0.0001',\n",
       " 'P(wors|book) = 0.0001',\n",
       " 'P(must|book) = 0.0001',\n",
       " 'P(bad|book) = 0.0001',\n",
       " 'P(meat|book) = 0.0001',\n",
       " 'P(sick|book) = 0.0001',\n",
       " 'P(second|book) = 0.0001',\n",
       " 'P(left|book) = 0.0001',\n",
       " 'P(buck|book) = 0.0001',\n",
       " 'P(cheaper|book) = 0.0001',\n",
       " 'P(nicer|book) = 0.0001',\n",
       " 'P(kid|book) = 0.0001',\n",
       " 'P(last|book) = 0.0001',\n",
       " 'P(fling|book) = 0.0001',\n",
       " 'P(school|book) = 0.0001',\n",
       " 'P(start|book) = 0.0001',\n",
       " 'P(attent|book) = 0.0001',\n",
       " 'P(littl|book) = 0.0001',\n",
       " 'P(consider|book) = 0.0001',\n",
       " 'P(attitud|book) = 0.0001',\n",
       " 'P(small|book) = 0.0001',\n",
       " 'P(tip|book) = 0.0001',\n",
       " 'P(huge|book) = 0.0001',\n",
       " 'P(complet|book) = 0.0001',\n",
       " 'P(glare|book) = 0.0001',\n",
       " 'P(involv|book) = 0.0001',\n",
       " 'P(air|book) = 0.0001',\n",
       " 'P(water|book) = 0.0001',\n",
       " 'P(underway|book) = 0.0001',\n",
       " 'P(plane|book) = 0.0001',\n",
       " 'P(fli|book) = 0.0001',\n",
       " 'P(firework|book) = 0.0001',\n",
       " 'P(navi|book) = 0.0001',\n",
       " 'P(pier|book) = 0.0001',\n",
       " 'P(sunday|book) = 0.0001',\n",
       " 'P(morn|book) = 0.0001',\n",
       " 'P(buffet|book) = 0.0001',\n",
       " 'P(price|book) = 0.0001',\n",
       " 'P(reason|book) = 0.0001',\n",
       " 'P(conceirg|book) = 0.0001',\n",
       " 'P(knowledg|book) = 0.0001',\n",
       " 'P(best|book) = 0.0001',\n",
       " 'P(ever|book) = 0.0001',\n",
       " 'P(overal|book) = 0.0001',\n",
       " 'P(properti|book) = 0.0001',\n",
       " 'P(incid|book) = 0.0001',\n",
       " 'P(none|book) = 0.0001',\n",
       " 'P(histori|book) = 0.0001',\n",
       " 'P(travel|book) = 0.0001',\n",
       " 'P(monaco|book) = 0.0001',\n",
       " 'P(monday|book) = 0.0001',\n",
       " 'P(march|book) = 0.0001',\n",
       " 'P(shortli|book) = 0.0001',\n",
       " 'P(retriev|book) = 0.0001',\n",
       " 'P(valet|book) = 0.0001',\n",
       " 'P(partner|book) = 0.0001',\n",
       " 'P(scrape|book) = 0.0001',\n",
       " 'P(bumper|book) = 0.0001',\n",
       " 'P(present|book) = 0.0001',\n",
       " 'P(durat|book) = 0.0001',\n",
       " 'P(approxim|book) = 0.0001',\n",
       " 'P(hour|book) = 0.0001',\n",
       " 'P(direct|book) = 0.0001',\n",
       " 'P(garag|book) = 0.0001',\n",
       " 'P(compani|book) = 0.0001',\n",
       " 'P(video|book) = 0.0001',\n",
       " 'P(within|book) = 0.0001',\n",
       " 'P(verifi|book) = 0.0001',\n",
       " 'P(unblemish|book) = 0.0001',\n",
       " 'P(departur|book) = 0.0001',\n",
       " 'P(mike|book) = 0.0001',\n",
       " 'P(yunan|book) = 0.0001',\n",
       " 'P(email|book) = 0.0001',\n",
       " 'P(exchang|book) = 0.0001',\n",
       " 'P(gener|book) = 0.0001',\n",
       " 'P(marco|book) = 0.0001',\n",
       " 'P(scherer|book) = 0.0001',\n",
       " 'P(file|book) = 0.0001',\n",
       " 'P(report|book) = 0.0001',\n",
       " 'P(claim|book) = 0.0001',\n",
       " 'P(insur|book) = 0.0001',\n",
       " 'P(deni|book) = 0.0001',\n",
       " 'P(admit|book) = 0.0001',\n",
       " 'P(fault|book) = 0.0001',\n",
       " 'P(liabil|book) = 0.0001',\n",
       " 'P(suppli|book) = 0.0001',\n",
       " 'P(enter|book) = 0.0001',\n",
       " 'P(exit|book) = 0.0001',\n",
       " 'P(damag|book) = 0.0001',\n",
       " 'P(checkin|book) = 0.0001',\n",
       " 'P(repres|book) = 0.0001',\n",
       " 'P(surveil|book) = 0.0001',\n",
       " 'P(contradict|book) = 0.0001',\n",
       " 'P(kimpton|book) = 0.0001',\n",
       " 'P(intouch|book) = 0.0001',\n",
       " 'P(stuck|book) = 0.0001',\n",
       " 'P(bill|book) = 0.0001',\n",
       " 'P(almost|book) = 0.0001',\n",
       " 'P(paint|book) = 0.0001',\n",
       " 'P(fee|book) = 0.0001',\n",
       " 'P(rental|book) = 0.0001',\n",
       " 'P(expens|book) = 0.0001',\n",
       " 'P(sever|book) = 0.0001',\n",
       " 'P(issu|book) = 0.0001',\n",
       " 'P(gigant|book) = 0.0001',\n",
       " 'P(headach|book) = 0.0001',\n",
       " 'P(busi|book) = 0.0001',\n",
       " 'P(possibl|book) = 0.0001',\n",
       " 'P(beyond|book) = 0.0001',\n",
       " 'P(mean|book) = 0.0001',\n",
       " 'P(incompet|book) = 0.0001',\n",
       " 'P(ran|book) = 0.0001',\n",
       " 'P(hot|book) = 0.0001',\n",
       " 'P(saturday|book) = 0.0001',\n",
       " 'P(slow|book) = 0.0001',\n",
       " 'P(given|book) = 0.0001',\n",
       " 'P(event|book) = 0.0001',\n",
       " 'P(red|book) = 0.0001',\n",
       " 'P(line|book) = 0.0001',\n",
       " 'P(train|book) = 0.0001',\n",
       " 'P(beneath|book) = 0.0001',\n",
       " 'P(citi|book) = 0.0001',\n",
       " 'P(thunder|book) = 0.0001',\n",
       " 'P(shouldnt|book) = 0.0001',\n",
       " 'P(awak|book) = 0.0001',\n",
       " 'P(toward|book) = 0.0001',\n",
       " 'P(nw|book) = 0.0001',\n",
       " 'P(airlin|book) = 0.0001',\n",
       " 'P(bonu|book) = 0.0001',\n",
       " 'P(point|book) = 0.0001',\n",
       " 'P(ok|book) = 0.0001',\n",
       " 'P(cup|book) = 0.0001',\n",
       " 'P(coffe|book) = 0.0001',\n",
       " 'P(aw|book) = 0.0001',\n",
       " 'P(wireless|book) = 0.0001',\n",
       " 'P(cabl|book) = 0.0001',\n",
       " 'P(channel|book) = 0.0001',\n",
       " 'P(fridg|book) = 0.0001',\n",
       " 'P(http|book) = 0.0001',\n",
       " 'P(hotelscom|book) = 0.0001',\n",
       " 'P(re|book) = 0.0001',\n",
       " 'P(tax|book) = 0.0001',\n",
       " 'P(expect|book) = 0.0001',\n",
       " 'P(superb|book) = 0.0001',\n",
       " 'P(conveni|book) = 0.0001',\n",
       " 'P(outweigh|book) = 0.0001',\n",
       " 'P(neg|book) = 0.0001',\n",
       " 'P(tripadvisor|book) = 0.0001',\n",
       " 'P(amen|book) = 0.0001',\n",
       " 'P(expedia|book) = 0.0001',\n",
       " 'P(stage|book) = 0.0001',\n",
       " 'P(sarita|book) = 0.0001',\n",
       " 'P(hopeless|book) = 0.0001',\n",
       " 'P(rude|book) = 0.0001',\n",
       " 'P(sort|book) = 0.0001',\n",
       " 'P(box|book) = 0.0001',\n",
       " 'P(hum|book) = 0.0001',\n",
       " 'P(turn|book) = 0.0001',\n",
       " 'P(seem|book) = 0.0001',\n",
       " 'P(condit|book) = 0.0001',\n",
       " 'P(let|book) = 0.0001',\n",
       " 'P(know|book) = 0.0001',\n",
       " 'P(major|book) = 0.0001',\n",
       " 'P(site|book) = 0.0001',\n",
       " 'P(roadwork|book) = 0.0001',\n",
       " 'P(truck|book) = 0.0001',\n",
       " 'P(beep|book) = 0.0001',\n",
       " 'P(continu|book) = 0.0001',\n",
       " 'P(everytim|book) = 0.0001',\n",
       " 'P(revers|book) = 0.0001',\n",
       " 'P(mayb|book) = 0.0001',\n",
       " 'P(plenti|book) = 0.0001',\n",
       " 'P(nearbi|book) = 0.0001',\n",
       " 'P(virgin|book) = 0.0001',\n",
       " 'P(atlant|book) = 0.0001',\n",
       " 'P(london|book) = 0.0001',\n",
       " 'P(quit|book) = 0.0001',\n",
       " 'P(reassur|book) = 0.0001',\n",
       " 'P(hilton|book) = 0.0001',\n",
       " 'P(brand|book) = 0.0001',\n",
       " 'P(name|book) = 0.0001',\n",
       " 'P(knew|book) = 0.0001',\n",
       " 'P(suggest|book) = 0.0001',\n",
       " 'P(arrriv|book) = 0.0001',\n",
       " 'P(warm|book) = 0.0001',\n",
       " 'P(quick|book) = 0.0001',\n",
       " 'P(effici|book) = 0.0001',\n",
       " 'P(interior|book) = 0.0001',\n",
       " 'P(spectacular|book) = 0.0001',\n",
       " 'P(refurbish|book) = 0.0001',\n",
       " 'P(reflect|book) = 0.0001',\n",
       " 'P(decor|book) = 0.0001',\n",
       " 'P(built|book) = 0.0001',\n",
       " 'P(queen|book) = 0.0001',\n",
       " 'P(particularli|book) = 0.0001',\n",
       " 'P(restaur|book) = 0.0001',\n",
       " 'P(ate|book) = 0.0001',\n",
       " 'P(gourmet|book) = 0.0001',\n",
       " 'P(lockwood|book) = 0.0001',\n",
       " 'P(valu|book) = 0.0001',\n",
       " 'P(qualiti|book) = 0.0001',\n",
       " 'P(offer|book) = 0.0001',\n",
       " 'P(touch|book) = 0.0001',\n",
       " 'P(destin|book) = 0.0001',\n",
       " 'P(supervis|book) = 0.0001',\n",
       " 'P(doormen|book) = 0.0001',\n",
       " 'P(saw|book) = 0.0001',\n",
       " 'P(assist|book) = 0.0001',\n",
       " 'P(thoroughli|book) = 0.0001',\n",
       " 'P(leisur|book) = 0.0001',\n",
       " 'P(money|book) = 0.0001',\n",
       " 'P(extrem|book) = 0.0001',\n",
       " 'P(recept|book) = 0.0001',\n",
       " 'P(courteou|book) = 0.0001',\n",
       " 'P(nd|book) = 0.0001',\n",
       " 'P(face|book) = 0.0001',\n",
       " 'P(john|book) = 0.0001',\n",
       " 'P(hancock|book) = 0.0001',\n",
       " 'P(tower|book) = 0.0001',\n",
       " 'P(housekeepingturn|book) = 0.0001',\n",
       " 'P(thorough|book) = 0.0001',\n",
       " 'P(replac|book) = 0.0001',\n",
       " 'P(choic|book) = 0.0001',\n",
       " 'P(subway|book) = 0.0001',\n",
       " 'P(awesom|book) = 0.0001',\n",
       " 'P(understand|book) = 0.0001',\n",
       " 'P(full|book) = 0.0001',\n",
       " 'P(clean|book) = 0.0001',\n",
       " 'P(space|book) = 0.0001',\n",
       " 'P(part|book) = 0.0001',\n",
       " 'P(especi|book) = 0.0001',\n",
       " 'P(nostalgia|book) = 0.0001',\n",
       " 'P(excel|book) = 0.0001',\n",
       " 'P(atmospher|book) = 0.0001',\n",
       " 'P(fairmont|book) = 0.0001',\n",
       " 'P(process|book) = 0.0001',\n",
       " 'P(painless|book) = 0.0001',\n",
       " 'P(disinterest|book) = 0.0001',\n",
       " 'P(procedur|book) = 0.0001',\n",
       " 'P(fine|book) = 0.0001',\n",
       " 'P(appreci|book) = 0.0001',\n",
       " 'P(warmer|book) = 0.0001',\n",
       " 'P(greet|book) = 0.0001',\n",
       " 'P(host|book) = 0.0001',\n",
       " 'P(see|book) = 0.0001',\n",
       " 'P(signageattende|book) = 0.0001',\n",
       " 'P(probabl|book) = 0.0001',\n",
       " 'P(separ|book) = 0.0001',\n",
       " 'P(confer|book) = 0.0001',\n",
       " 'P(speedi|book) = 0.0001',\n",
       " 'P(parkview|book) = 0.0001',\n",
       " 'P(millenium|book) = 0.0001',\n",
       " 'P(anteroom|book) = 0.0001',\n",
       " 'P(sofa|book) = 0.0001',\n",
       " 'P(minibar|book) = 0.0001',\n",
       " 'P(sink|book) = 0.0001',\n",
       " 'P(maker|book) = 0.0001',\n",
       " 'P(dine|book) = 0.0001',\n",
       " 'P(appear|book) = 0.0001',\n",
       " 'P(standard|book) = 0.0001',\n",
       " 'P(slightli|book) = 0.0001',\n",
       " 'P(similar|book) = 0.0001',\n",
       " 'P(upscal|book) = 0.0001',\n",
       " 'P(overtli|book) = 0.0001',\n",
       " 'P(shoe|book) = 0.0001',\n",
       " 'P(shine|book) = 0.0001',\n",
       " 'P(station|book) = 0.0001',\n",
       " 'P(extra|book) = 0.0001',\n",
       " 'P(collar|book) = 0.0001',\n",
       " 'P(tab|book) = 0.0001',\n",
       " 'P(pepper|book) = 0.0001',\n",
       " 'P(throughout|book) = 0.0001',\n",
       " 'P(activ|book) = 0.0001',\n",
       " 'P(perfectli|book) = 0.0001',\n",
       " 'P(aria|book) = 0.0001',\n",
       " 'P(oddli|book) = 0.0001',\n",
       " 'P(new|book) = 0.0001',\n",
       " 'P(rememb|book) = 0.0001',\n",
       " 'P(seat|book) = 0.0001',\n",
       " 'P(minor|book) = 0.0001',\n",
       " 'P(nondown|book) = 0.0001',\n",
       " 'P(serious|book) = 0.0001',\n",
       " 'P(bare|book) = 0.0001',\n",
       " 'P(felt|book) = 0.0001',\n",
       " 'P(suffer|book) = 0.0001',\n",
       " 'P(congest|book) = 0.0001',\n",
       " 'P(neck|book) = 0.0001',\n",
       " 'P(support|book) = 0.0001',\n",
       " 'P(attend|book) = 0.0001',\n",
       " 'P(overli|book) = 0.0001',\n",
       " 'P(eager|book) = 0.0001',\n",
       " 'P(mention|book) = 0.0001',\n",
       " 'P(improv|book) = 0.0001',\n",
       " 'P(featur|book) = 0.0001',\n",
       " 'P(brief|book) = 0.0001',\n",
       " 'P(comment|book) = 0.0001',\n",
       " 'P(section|book) = 0.0001',\n",
       " 'P(presid|book) = 0.0001',\n",
       " 'P(club|book) = 0.0001',\n",
       " 'P(membership|book) = 0.0001',\n",
       " 'P(director|book) = 0.0001',\n",
       " 'P(discuss|book) = 0.0001',\n",
       " 'P(essenti|book) = 0.0001',\n",
       " 'P(thank|book) = 0.0001',\n",
       " 'P(kudo|book) = 0.0001',\n",
       " 'P(custom|book) = 0.0001',\n",
       " 'P(loyalti|book) = 0.0001',\n",
       " 'P(kind|book) = 0.0001',\n",
       " 'P(avail|book) = 0.0001',\n",
       " 'P(squeez|book) = 0.0001',\n",
       " 'P(adult|book) = 0.0001',\n",
       " 'P(ladi|book) = 0.0001',\n",
       " 'P(singl|book) = 0.0001',\n",
       " 'P(blowup|book) = 0.0001',\n",
       " 'P(pile|book) = 0.0001',\n",
       " 'P(furnitur|book) = 0.0001',\n",
       " 'P(unsatisfactori|book) = 0.0001',\n",
       " 'P(tell|book) = 0.0001',\n",
       " 'P(peopl|book) = 0.0001',\n",
       " 'P(pari|book) = 0.0001',\n",
       " 'P(nextspr|book) = 0.0001',\n",
       " 'P(intend|book) = 0.0001',\n",
       " 'P(headquart|book) = 0.0001',\n",
       " 'P(facil|book) = 0.0001',\n",
       " 'P(swissotel|book) = 0.0001',\n",
       " 'P(importantli|book) = 0.0001',\n",
       " 'P(heard|book) = 0.0001',\n",
       " 'P(hallway|book) = 0.0001',\n",
       " 'P(downsid|book) = 0.0001',\n",
       " 'P(special|book) = 0.0001',\n",
       " 'P(cater|book) = 0.0001',\n",
       " 'P(wealthi|book) = 0.0001',\n",
       " 'P(andor|book) = 0.0001',\n",
       " 'P(client|book) = 0.0001',\n",
       " 'P(ridicul|book) = 0.0001',\n",
       " 'P(howev|book) = 0.0001',\n",
       " 'P(prior|book) = 0.0001',\n",
       " 'P(ie|book) = 0.0001',\n",
       " 'P(bring|book) = 0.0001',\n",
       " 'P(snack|book) = 0.0001',\n",
       " 'P(microfridg|book) = 0.0001',\n",
       " 'P(bellmen|book) = 0.0001',\n",
       " 'P(instantli|book) = 0.0001',\n",
       " 'P(impress|book) = 0.0001',\n",
       " 'P(abl|book) = 0.0001',\n",
       " 'P(print|book) = 0.0001',\n",
       " 'P(board|book) = 0.0001',\n",
       " 'P(pass|book) = 0.0001',\n",
       " 'P(frustrat|book) = 0.0001',\n",
       " 'P(nowaday|book) = 0.0001',\n",
       " 'P(loud|book) = 0.0001',\n",
       " 'P(may|book) = 0.0001',\n",
       " 'P(neighbor|book) = 0.0001',\n",
       " 'P(sheraton|book) = 0.0001',\n",
       " 'P(royal|book) = 0.0001',\n",
       " 'P(orchid|book) = 0.0001',\n",
       " 'P(bangkok|book) = 0.0001',\n",
       " 'P(year|book) = 0.0001',\n",
       " 'P(ago|book) = 0.0001',\n",
       " 'P(forward|book) = 0.0001',\n",
       " 'P(repeat|book) = 0.0001',\n",
       " 'P(unfortun|book) = 0.0001',\n",
       " 'P(met|book) = 0.0001',\n",
       " 'P(palmer|book) = 0.0001',\n",
       " 'P(hous|book) = 0.0001',\n",
       " 'P(pro|book) = 0.0001',\n",
       " 'P(river|book) = 0.0001',\n",
       " 'P(rest|book) = 0.0001',\n",
       " 'P(wifi|book) = 0.0001',\n",
       " 'P(provid|book) = 0.0001',\n",
       " 'P(work|book) = 0.0001',\n",
       " 'P(environ|book) = 0.0001',\n",
       " 'P(omelett|book) = 0.0001',\n",
       " 'P(crepe|book) = 0.0001',\n",
       " 'P(french|book) = 0.0001',\n",
       " 'P(toast|book) = 0.0001',\n",
       " 'P(con|book) = 0.0001',\n",
       " 'P(assign|book) = 0.0001',\n",
       " 'P(prepaid|book) = 0.0001',\n",
       " 'P(filthi|book) = 0.0001',\n",
       " 'P(previou|book) = 0.0001',\n",
       " 'P(hang|book) = 0.0001',\n",
       " 'P(unimpress|book) = 0.0001',\n",
       " 'P(bathtubshow|book) = 0.0001',\n",
       " 'P(combin|book) = 0.0001',\n",
       " 'P(worn|book) = 0.0001',\n",
       " 'P(plumb|book) = 0.0001',\n",
       " 'P(set|book) = 0.0001',\n",
       " 'P(soft|book) = 0.0001',\n",
       " 'P(chair|book) = 0.0001',\n",
       " 'P(slam|book) = 0.0001',\n",
       " 'P(noisili|book) = 0.0001',\n",
       " 'P(nearest|book) = 0.0001',\n",
       " 'P(lstation|book) = 0.0001',\n",
       " 'P(explain|book) = 0.0001',\n",
       " 'P(mercuri|book) = 0.0001',\n",
       " 'P(theatr|book) = 0.0001',\n",
       " 'P(map|book) = 0.0001',\n",
       " 'P(starbuck|book) = 0.0001',\n",
       " 'P(downstair|book) = 0.0001',\n",
       " 'P(link|book) = 0.0001',\n",
       " 'P(cafe|book) = 0.0001',\n",
       " 'P(complimentari|book) = 0.0001',\n",
       " 'P(newspap|book) = 0.0001',\n",
       " 'P(deliv|book) = 0.0001',\n",
       " 'P(folio|book) = 0.0001',\n",
       " 'P(comput|book) = 0.0001',\n",
       " 'P(without|book) = 0.0001',\n",
       " 'P(hesit|book) = 0.0001',\n",
       " 'P(attract|book) = 0.0001',\n",
       " 'P(obtain|book) = 0.0001',\n",
       " 'P(preferenti|book) = 0.0001',\n",
       " 'P(health|book) = 0.0001',\n",
       " 'P(join|book) = 0.0001',\n",
       " 'P(cost|book) = 0.0001',\n",
       " 'P(ten|book) = 0.0001',\n",
       " 'P(dollar|book) = 0.0001',\n",
       " 'P(updat|book) = 0.0001',\n",
       " 'P(except|book) = 0.0001',\n",
       " 'P(mostli|book) = 0.0001',\n",
       " 'P(overpr|book) = 0.0001',\n",
       " 'P(cart|book) = 0.0001',\n",
       " 'P(underground|book) = 0.0001',\n",
       " 'P(millennium|book) = 0.0001',\n",
       " 'P(pricelinecom|book) = 0.0001',\n",
       " 'P(getaway|book) = 0.0001',\n",
       " 'P(midway|book) = 0.0001',\n",
       " 'P(orang|book) = 0.0001',\n",
       " 'P(easi|book) = 0.0001',\n",
       " 'P(uncomfort|book) = 0.0001',\n",
       " 'P(neighborhoodarea|book) = 0.0001',\n",
       " 'P(homeless|book) = 0.0001',\n",
       " 'P(panhandl|book) = 0.0001',\n",
       " 'P(ride|book) = 0.0001',\n",
       " 'P(attractionsshoppingrestaur|book) = 0.0001',\n",
       " 'P(gawdi|book) = 0.0001',\n",
       " 'P(colorsdecor|book) = 0.0001',\n",
       " 'P(cruis|book) = 0.0001',\n",
       " 'P(ship|book) = 0.0001',\n",
       " 'P(annoy|book) = 0.0001',\n",
       " 'P(whatsoev|book) = 0.0001',\n",
       " 'P(thin|book) = 0.0001',\n",
       " 'P(greatli|book) = 0.0001',\n",
       " 'P(exagger|book) = 0.0001',\n",
       " 'P(concret|book) = 0.0001',\n",
       " 'P(thick|book) = 0.0001',\n",
       " 'P(noth|book) = 0.0001',\n",
       " 'P(highli|book) = 0.0001',\n",
       " 'P(crowd|book) = 0.0001',\n",
       " 'P(old|book) = 0.0001',\n",
       " 'P(roomsveri|book) = 0.0001',\n",
       " 'P(actual|book) = 0.0001',\n",
       " 'P(compel|book) = 0.0001',\n",
       " 'P(write|book) = 0.0001',\n",
       " 'P(fall|book) = 0.0001',\n",
       " 'P(asleep|book) = 0.0001',\n",
       " 'P(chat|book) = 0.0001',\n",
       " 'P(friend|book) = 0.0001',\n",
       " 'P(gossip|book) = 0.0001',\n",
       " 'P(unprofession|book) = 0.0001',\n",
       " 'P(high|book) = 0.0001',\n",
       " 'P(ha|book) = 0.0001',\n",
       " 'P(bag|book) = 0.0001',\n",
       " 'P(grape|book) = 0.0001',\n",
       " 'P(behind|book) = 0.0001',\n",
       " 'P(sill|book) = 0.0001',\n",
       " 'P(hair|book) = 0.0001',\n",
       " 'P(bathtub|book) = 0.0001',\n",
       " 'P(done|book) = 0.0001',\n",
       " 'P(reclean|book) = 0.0001',\n",
       " 'P(bottl|book) = 0.0001',\n",
       " 'P(clerk|book) = 0.0001',\n",
       " 'P(come|book) = 0.0001',\n",
       " 'P(key|book) = 0.0001',\n",
       " 'P(item|book) = 0.0001',\n",
       " 'P(king|book) = 0.0001',\n",
       " 'P(memori|book) = 0.0001',\n",
       " 'P(bargain|book) = 0.0001',\n",
       " 'P(live|book) = 0.0001',\n",
       " 'P(couch|book) = 0.0001',\n",
       " 'P(closet|book) = 0.0001',\n",
       " 'P(renov|book) = 0.0001',\n",
       " 'P(bu|book) = 0.0001',\n",
       " 'P(fivestar|book) = 0.0001',\n",
       " 'P(note|book) = 0.0001',\n",
       " 'P(nonsuit|book) = 0.0001',\n",
       " 'P(june|book) = 0.0001',\n",
       " 'P(tag|book) = 0.0001',\n",
       " 'P(along|book) = 0.0001',\n",
       " 'P(flew|book) = 0.0001',\n",
       " 'P(ohar|book) = 0.0001',\n",
       " 'P(everybodi|book) = 0.0001',\n",
       " 'P(overlook|book) = 0.0001',\n",
       " 'P(hardli|book) = 0.0001',\n",
       " 'P(bother|book) = 0.0001',\n",
       " 'P(awaken|book) = 0.0001',\n",
       " 'P(light|book) = 0.0001',\n",
       " 'P(sleeper|book) = 0.0001',\n",
       " 'P(comfi|book) = 0.0001',\n",
       " 'P(lunch|book) = 0.0001',\n",
       " 'P(meal|book) = 0.0001',\n",
       " 'P(perfect|book) = 0.0001',\n",
       " 'P(ca|book) = 0.0001',\n",
       " 'P(beat|book) = 0.0001',\n",
       " 'P(ador|book) = 0.0001',\n",
       " 'P(pet|book) = 0.0001',\n",
       " 'P(store|book) = 0.0001',\n",
       " 'P(tail|book) = 0.0001',\n",
       " 'P(across|book) = 0.0001',\n",
       " 'P(brought|book) = 0.0001',\n",
       " 'P(dog|book) = 0.0001',\n",
       " 'P(toy|book) = 0.0001',\n",
       " 'P(safe|book) = 0.0001',\n",
       " 'P(neighborhoodi|book) = 0.0001',\n",
       " 'P(midlevel|book) = 0.0001',\n",
       " 'P(blown|book) = 0.0001',\n",
       " 'P(social|book) = 0.0001',\n",
       " 'P(watch|book) = 0.0001',\n",
       " 'P(scene|book) = 0.0001',\n",
       " 'P(swank|book) = 0.0001',\n",
       " 'P(smooth|book) = 0.0001',\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_addk_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small constant probability for <unk> tokens\n",
    "import math\n",
    "UNK_PROB = 1e-3  # You can adjust this value as needed\n",
    "\n",
    "def calc_addk_probabilities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Calculate unigram probabilities for the sentence\n",
    "    # Calculate bigram probabilities for the sentence\n",
    "    log_combined_prob = 0\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1 = tokens[i]\n",
    "        w2 = tokens[i + 1]\n",
    "        # Check bigram probability with fallback for unknown tokens\n",
    "        if w1 in bigram_probabs_addk and w2 in bigram_probabs_addk[w1]:\n",
    "            prob = bigram_probabs_addk[w1][w2]\n",
    "        else:\n",
    "            prob = UNK_PROB  # Use small constant probability for unknown bigram\n",
    "\n",
    "        log_combined_prob += math.log(prob)\n",
    "\n",
    "    # Convert log probability back to probability\n",
    "\n",
    "    return log_combined_prob\n",
    "\n",
    "\n",
    "#result = calc_probabilities('book two room four month advanc talbott place top floor next elev use night long speak front desk told simpli honor request upper floor request better view look brick wall get sleep also told receiv complaint guest th floor awar nois problem place us floor hotel total book request upper floor constitut place someon top floor use request justifi decid stay request room lower floor away elev spoke length book two room prefer simpli poor treatment guest believ would complain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['log_prob_addk'] = df_test['filtered'].apply(lambda x: pd.Series(calc_addk_probabilities(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "addk_perplexity = calculate_perplexity(df_test, 'log_prob_addk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add-K perplexity:  8.886155978047483\n"
     ]
    }
   ],
   "source": [
    "print(\"Add-K perplexity: \", addk_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
